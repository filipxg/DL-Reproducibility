{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:16:50.058940Z","iopub.status.busy":"2024-04-14T12:16:50.058259Z","iopub.status.idle":"2024-04-14T12:16:50.069971Z","shell.execute_reply":"2024-04-14T12:16:50.069038Z","shell.execute_reply.started":"2024-04-14T12:16:50.058904Z"},"trusted":true},"outputs":[],"source":["import os\n","import sys\n","sys.path.insert(1, \"/kaggle/input/3d-unet\")"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-14T12:16:51.212786Z","iopub.status.busy":"2024-04-14T12:16:51.212039Z","iopub.status.idle":"2024-04-14T12:16:53.261373Z","shell.execute_reply":"2024-04-14T12:16:53.260537Z","shell.execute_reply.started":"2024-04-14T12:16:51.212751Z"},"trusted":true},"outputs":[],"source":["import torch\n","import cv2\n","import numpy as np\n","from skimage import io\n","from pytorch3dunet.unet3d.model import UNet3D"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:16:59.392614Z","iopub.status.busy":"2024-04-14T12:16:59.391091Z","iopub.status.idle":"2024-04-14T12:16:59.397737Z","shell.execute_reply":"2024-04-14T12:16:59.396608Z","shell.execute_reply.started":"2024-04-14T12:16:59.392565Z"},"trusted":true},"outputs":[],"source":["def binarize(mask: torch.tensor) -> torch.tensor:\n","    return torch.where(mask != 0, 1, 0)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:17:00.983381Z","iopub.status.busy":"2024-04-14T12:17:00.983034Z","iopub.status.idle":"2024-04-14T12:17:02.692335Z","shell.execute_reply":"2024-04-14T12:17:02.691452Z","shell.execute_reply.started":"2024-04-14T12:17:00.983354Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from scipy.ndimage import zoom\n","import cv2\n","import torch.nn.functional as F\n","\n","class EmbryoDataset(Dataset):\n","    \n","    def __init__(self, image_dir_path: str, gt_dir_path: str, augment: bool = False):\n","        self.image_dir_path = image_dir_path\n","        self.gt_dir_path = gt_dir_path\n","        self._filenames = os.listdir(image_dir_path)\n","        self._augment = augment\n","        \n","        if self._augment:\n","            self._filenames = self._filenames * 4\n","        \n","    def __len__(self):\n","        return len(self._filenames)\n","    \n","    def __preprocess_image(self, image: torch.Tensor) -> torch.Tensor:\n","        min_value = torch.min(image)\n","        max_value = torch.max(image)\n","        \n","        image = (image - min_value) / (max_value - min_value)\n","        \n","        return image\n","    \n","    def __preprocess_gt(self, gt: torch.Tensor) -> torch.Tensor:\n","        gt = binarize(gt)\n","        \n","        return gt\n","    \n","    def __preprocess(self, raw: np.ndarray, type: int) -> np.ndarray:\n","        preprocessed = raw.astype(np.float32)\n","        x, y = preprocessed.shape[1], preprocessed.shape[2]\n","        x_scale_factor = 128 / x\n","        y_scale_factor = 128 / y\n","        preprocessed = zoom(preprocessed, (2.1875, x_scale_factor, y_scale_factor), order=3)\n","        \n","        preprocessed = torch.from_numpy(preprocessed)\n","        preprocessed = preprocessed.to(\"cuda\", dtype=torch.float32)\n","        preprocessed = preprocessed.unsqueeze(dim=0)\n","        \n","        if type == 0:\n","            preprocessed = self.__preprocess_image(preprocessed)\n","        if type == 1:\n","            preprocessed = self.__preprocess_gt(preprocessed)\n","            \n","        return preprocessed\n","\n","    def __getitem__(self, idx):\n","        if self._augment:\n","            original_idx = idx // 4\n","        else:\n","            original_idx = idx\n","\n","        curr_filename = self._filenames[original_idx]\n","        curr_image_path = os.path.join(self.image_dir_path, curr_filename)\n","        curr_gt_path = os.path.join(self.gt_dir_path, curr_filename)\n","\n","        image_raw = io.imread(curr_image_path)\n","        gt_raw = io.imread(curr_gt_path)\n","        \n","        x = self.__preprocess(image_raw, type=0)\n","        y = self.__preprocess(gt_raw, type=1)\n","\n","        if self._augment:\n","            transform_type = idx % 4\n","        \n","            # Apply the specific transformation\n","            if transform_type == 1:  # Flip horizontally\n","                x = transforms.functional.hflip(x)\n","                y = transforms.functional.hflip(y)\n","            elif transform_type == 2:  # Flip vertically\n","                x = transforms.functional.vflip(x)\n","                y = transforms.functional.vflip(y)\n","            elif transform_type == 3:  # Flip both horizontally and vertically\n","                x = transforms.functional.hflip(x)\n","                y = transforms.functional.hflip(y)\n","        \n","        return (x, y)"]},{"cell_type":"markdown","metadata":{},"source":["The loss gave us negative outputs, so i rewrote the loss function to follow https://arxiv.org/pdf/1606.04797.pdf since that is what the github mentions. This is the formula used:\n","\n","$$D = \\frac{2\\sum_i^N p_i g_i}{\\sum_i^N p_i^2 + \\sum_i^N g_i^2}$$\n","\n","where the sums run over the $N$ voxels, of the predicted binary segmentation volume $p_i \\in P$ and the ground truth binary volume $g_i \\in G$."]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:17:05.107376Z","iopub.status.busy":"2024-04-14T12:17:05.106816Z","iopub.status.idle":"2024-04-14T12:17:05.113646Z","shell.execute_reply":"2024-04-14T12:17:05.112695Z","shell.execute_reply.started":"2024-04-14T12:17:05.107345Z"},"trusted":true},"outputs":[],"source":["def dice_loss(input, target):\n","    # Flatten the tensors to make sure you can sum over all voxels\n","    input_flat = input.view(-1)\n","    target_flat = target.view(-1)\n","    \n","    intersection = 2.0 * (input_flat * target_flat).sum()\n","    denominator = input_flat.pow(2).sum() + target_flat.pow(2).sum()\n","    \n","    dice_score = intersection / denominator.clamp(min=1e-6)\n","    return 1 - dice_score"]},{"cell_type":"markdown","metadata":{},"source":["## 3D Unet hyperparameter tuning"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:17:06.614259Z","iopub.status.busy":"2024-04-14T12:17:06.613913Z","iopub.status.idle":"2024-04-14T12:17:06.622283Z","shell.execute_reply":"2024-04-14T12:17:06.621176Z","shell.execute_reply.started":"2024-04-14T12:17:06.614235Z"},"trusted":true},"outputs":[],"source":["train_set = EmbryoDataset(image_dir_path=\"/kaggle/input/dl-reprod/Images/train/Images\", gt_dir_path=\"/kaggle/input/dl-reprod/GroundTruth/train/GroundTruth_QCANet\", augment=True)\n","test_set = EmbryoDataset(image_dir_path=\"/kaggle/input/dl-reprod/Images/test/Images\", gt_dir_path=\"/kaggle/input/dl-reprod/GroundTruth/test/GroundTruth_QCANet\", augment=False)\n","train_loader = DataLoader(train_set, batch_size=1, shuffle=True)\n","test_loader = DataLoader(test_set, batch_size=1, shuffle=False)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:17:07.683033Z","iopub.status.busy":"2024-04-14T12:17:07.682254Z","iopub.status.idle":"2024-04-14T12:17:08.007745Z","shell.execute_reply":"2024-04-14T12:17:08.006914Z","shell.execute_reply.started":"2024-04-14T12:17:07.682996Z"},"trusted":true},"outputs":[],"source":["model = UNet3D(in_channels=1, out_channels=1).cuda()\n","optimizer = torch.optim.Adam(model.parameters(), lr=4.617614178775834e-05)"]},{"cell_type":"code","execution_count":8,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-04-14T12:17:10.036574Z","iopub.status.busy":"2024-04-14T12:17:10.036182Z","iopub.status.idle":"2024-04-14T12:17:18.239405Z","shell.execute_reply":"2024-04-14T12:17:18.238135Z","shell.execute_reply.started":"2024-04-14T12:17:10.036542Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2024-04-14 12:17:10,437] A new study created in memory with name: no-name-7561f283-4f88-414e-b4df-c50a35654119\n","  0%|          | 1/484 [00:07<57:43,  7.17s/it]\n","[W 2024-04-14 12:17:17,616] Trial 0 failed with parameters: {'learning_rate': 6.084507237396047e-05} because of the following error: KeyboardInterrupt().\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n","    value_or_values = func(trial)\n","  File \"/tmp/ipykernel_103/329070226.py\", line 22, in objective\n","    total_loss += loss.item()\n","KeyboardInterrupt\n","[W 2024-04-14 12:17:17,618] Trial 0 failed with value None.\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Optuna study\u001b[39;00m\n\u001b[1;32m     29\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m, sampler\u001b[38;5;241m=\u001b[39mTPESampler())\n\u001b[0;32m---> 30\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Best trial result\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n","Cell \u001b[0;32mIn[8], line 22\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     20\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     21\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 22\u001b[0m         total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     average_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Here you can also implement validation and use the validation loss as the return value\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import optuna\n","from optuna.samplers import TPESampler\n","from tqdm import tqdm\n","\n","def objective(trial):\n","    # Suggested hyperparameters\n","    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True)\n","    \n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    # Training loop\n","    model.train()\n","    for epoch in range(10):\n","        total_loss = 0\n","        for data in tqdm(train_loader):\n","            x, y = data\n","            optimizer.zero_grad()\n","            y_pred = model.forward(x)\n","            loss = dice_loss(y_pred, y)\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item()\n","        average_loss = total_loss / len(train_loader)\n","\n","    # Here you can also implement validation and use the validation loss as the return value\n","    return average_loss\n","\n","# Optuna study\n","study = optuna.create_study(direction=\"minimize\", sampler=TPESampler())\n","study.optimize(objective, n_trials=10)\n","\n","# Best trial result\n","print(\"Best trial:\")\n","trial = study.best_trial\n","print(f\"Value: {trial.value}\")\n","print(\"Params: \")\n","for key, value in trial.params.items():\n","    print(f\"    {key}: {value}\")"]},{"cell_type":"markdown","metadata":{},"source":["# NSN and NDN train and test functions"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:17:21.317907Z","iopub.status.busy":"2024-04-14T12:17:21.317047Z","iopub.status.idle":"2024-04-14T12:17:21.323464Z","shell.execute_reply":"2024-04-14T12:17:21.322508Z","shell.execute_reply.started":"2024-04-14T12:17:21.317872Z"},"trusted":true},"outputs":[],"source":["def separate_channels(mask: torch.tensor) -> torch.tensor:\n","    class_labels = [0,1]\n","    gt = torch.zeros((len(class_labels), mask.shape[1], mask.shape[2], mask.shape[3]))\n","    \n","    for class_label in class_labels:\n","        gt[class_label] = torch.where(mask == class_label, 1, 0)\n","        \n","    return gt"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:17:25.574999Z","iopub.status.busy":"2024-04-14T12:17:25.574354Z","iopub.status.idle":"2024-04-14T12:17:25.591258Z","shell.execute_reply":"2024-04-14T12:17:25.590130Z","shell.execute_reply.started":"2024-04-14T12:17:25.574968Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from scipy.ndimage import zoom\n","import cv2\n","import torch.nn.functional as F\n","\n","class EmbryoDataset(Dataset):\n","    \n","    def __init__(self, image_dir_path: str, gt_dir_path: str, augment: bool = False):\n","        self.image_dir_path = image_dir_path\n","        self.gt_dir_path = gt_dir_path\n","        self._filenames = os.listdir(image_dir_path)\n","        self._augment = augment\n","        \n","        if self._augment:\n","            self._filenames = self._filenames * 4\n","        \n","    def __len__(self):\n","        return len(self._filenames)\n","    \n","    def __preprocess_image(self, image: torch.Tensor) -> torch.Tensor:\n","        min_value = torch.min(image)\n","        max_value = torch.max(image)\n","        \n","        image = (image - min_value) / (max_value - min_value)\n","        \n","        return image\n","    \n","    def __preprocess_gt(self, gt: torch.Tensor) -> torch.Tensor:\n","        gt = separate_channels(gt)\n","        \n","        return gt\n","    \n","    def __preprocess(self, raw: np.ndarray, type: int) -> np.ndarray:\n","        preprocessed = raw.astype(np.float32)\n","        x, y = preprocessed.shape[1], preprocessed.shape[2]\n","        x_scale_factor = 128 / x\n","        y_scale_factor = 128 / y\n","        preprocessed = zoom(preprocessed, (2.1875, x_scale_factor, y_scale_factor), order=3)\n","        \n","        preprocessed = torch.from_numpy(preprocessed)\n","        preprocessed = preprocessed.to(\"cuda\", dtype=torch.float32)\n","        preprocessed = preprocessed.unsqueeze(dim=0)\n","        \n","        if type == 0:\n","            preprocessed = self.__preprocess_image(preprocessed)\n","        if type == 1:\n","            preprocessed = self.__preprocess_gt(preprocessed)\n","            \n","        return preprocessed\n","\n","    def __getitem__(self, idx):\n","        if self._augment:\n","            original_idx = idx // 4\n","        else:\n","            original_idx = idx\n","\n","        curr_filename = self._filenames[original_idx]\n","        curr_image_path = os.path.join(self.image_dir_path, curr_filename)\n","        curr_gt_path = os.path.join(self.gt_dir_path, curr_filename)\n","\n","        image_raw = io.imread(curr_image_path)\n","        gt_raw = io.imread(curr_gt_path)\n","        \n","        x = self.__preprocess(image_raw, type=0)\n","        y = self.__preprocess(gt_raw, type=1)\n","\n","        if self._augment:\n","            transform_type = idx % 4\n","        \n","            # Apply the specific transformation\n","            if transform_type == 1:  # Flip horizontally\n","                x = transforms.functional.hflip(x)\n","                y = transforms.functional.hflip(y)\n","            elif transform_type == 2:  # Flip vertically\n","                x = transforms.functional.vflip(x)\n","                y = transforms.functional.vflip(y)\n","            elif transform_type == 3:  # Flip both horizontally and vertically\n","                x = transforms.functional.hflip(x)\n","                y = transforms.functional.hflip(y)\n","        \n","        return (x.cuda(), y.cuda())"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:17:27.695784Z","iopub.status.busy":"2024-04-14T12:17:27.695095Z","iopub.status.idle":"2024-04-14T12:17:27.704177Z","shell.execute_reply":"2024-04-14T12:17:27.703168Z","shell.execute_reply.started":"2024-04-14T12:17:27.695748Z"},"trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","\n","def train_epoch():\n","    total_loss = 0\n","    with tqdm(total=len(train_set)) as pbar:\n","        for i, data in enumerate(train_loader):\n","            x, y = data\n","            optimizer.zero_grad()\n","            y_pred = model.forward(x)\n","            # loss, y_pred = model.forward(x, t=y, seg=False)\n","            loss = dice_loss(y_pred, y)\n","            loss.backward()\n","            optimizer.step()\n","            \n","            total_loss += loss.item()\n","            pbar.update(1)\n","    return total_loss / len(train_loader)\n","\n","def test_epoch():\n","    total_loss = 0\n","    total_iou = 0\n","    with torch.no_grad():\n","        for i, data in enumerate(test_loader):\n","            x_test, y_test = data\n","            y_pred = model(x_test)\n","            loss = dice_loss(y_pred, y_test)\n","            iou_value = iou(y_pred, y_test)\n","            total_loss += loss.item()\n","            total_iou += iou_value.item()\n","    return total_loss / len(test_loader), total_iou / len(test_loader)"]},{"cell_type":"markdown","metadata":{},"source":["## NSN hyperparameter tuning"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:17:30.166833Z","iopub.status.busy":"2024-04-14T12:17:30.166471Z","iopub.status.idle":"2024-04-14T12:17:30.237020Z","shell.execute_reply":"2024-04-14T12:17:30.236034Z","shell.execute_reply.started":"2024-04-14T12:17:30.166804Z"},"trusted":true},"outputs":[],"source":["from torch import nn\n","\n","class Model_L2(nn.Module):\n","    def __init__(\n","            self,\n","            ndim=3,\n","            n_class=2,\n","            init_channel=2,\n","            kernel_size=3,\n","            pool_size=2,\n","            ap_factor=2,\n","            gpu=-1,\n","            loss_func='nn.CrossEntropyLoss'\n","        ):\n","        super(Model_L2, self).__init__()\n","        self.gpu = gpu\n","        self.pool_size = pool_size\n","        self.phase = 'train'\n","        self.loss_func = eval(loss_func)()\n","\n","        self.c0=nn.Conv3d(1, init_channel, kernel_size, 1, int(kernel_size/2))\n","        self.c1=nn.Conv3d(init_channel, int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.c2=nn.Conv3d(int(init_channel * (ap_factor ** 1)), int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","        self.c3=nn.Conv3d(int(init_channel * (ap_factor ** 1)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.c4=nn.Conv3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","        self.c5=nn.Conv3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 3)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.dc0=nn.ConvTranspose3d(int(init_channel * (ap_factor ** 3)), int(init_channel * (ap_factor ** 3)), self.pool_size, self.pool_size, 0)\n","        self.dc1=nn.Conv3d(int(init_channel * (ap_factor ** 2) + init_channel * (ap_factor ** 3)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","        self.dc2=nn.Conv3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.dc3=nn.ConvTranspose3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 2)), self.pool_size, self.pool_size, 0)\n","        self.dc4=nn.Conv3d(int(init_channel * (ap_factor ** 1) + init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","        self.dc5=nn.Conv3d(int(init_channel * (ap_factor ** 1)), int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.dc6=nn.Conv3d(int(init_channel * (ap_factor ** 1)), n_class, 1, 1)\n","\n","        self.bnc0=nn.BatchNorm3d(init_channel)\n","        self.bnc1=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","\n","        self.bnc2=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","        self.bnc3=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","\n","        self.bnc4=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","        self.bnc5=nn.BatchNorm3d(int(init_channel * (ap_factor ** 3)))\n","\n","        self.bndc1=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","        self.bndc2=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","        self.bndc4=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","        self.bndc5=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","\n","        self.pool = nn.MaxPool3d(pool_size, pool_size)\n","\n","    def _calc(self, x):\n","        e0 = F.relu(self.bnc0(self.c0(x)))\n","        syn0 = F.relu(self.bnc1(self.c1(e0)))\n","        del e0\n","        e1 = self.pool(syn0)\n","        e2 = F.relu(self.bnc2(self.c2(e1)))\n","        syn1 = F.relu(self.bnc3(self.c3(e2)))\n","        del e1, e2\n","        e3 = self.pool(syn1)\n","        e4 = F.relu(self.bnc4(self.c4(e3)))\n","        e5 = F.relu(self.bnc5(self.c5(e4)))\n","        del e3, e4\n","        d0 = torch.cat([self.dc0(e5), syn1], dim=1)\n","        del e5, syn1\n","        d1 = F.relu(self.bndc1(self.dc1(d0)))\n","        d2 = F.relu(self.bndc2(self.dc2(d1)))\n","        del d0, d1\n","        d3 = torch.cat([self.dc3(d2), syn0], dim=1)\n","        del d2, syn0\n","        d4 = F.relu(self.bndc4(self.dc4(d3)))\n","        d5 = F.relu(self.bndc5(self.dc5(d4)))\n","        del d3, d4\n","        d6 = self.dc6(d5)\n","        del d5\n","        return d6\n","\n","    def forward(self, x, t=None, seg=True):\n","        h = self._calc(x)\n","        if seg:\n","            pred = F.softmax(h, dim=1)\n","            del h\n","            return pred\n","        else:\n","            loss = self.loss_func(h, t.float())\n","            pred = F.softmax(h, dim=1)\n","            del h\n","            return loss, pred.data\n","        \n","class Model_L2_Sigmoid(nn.Module):\n","    def __init__(\n","            self,\n","            ndim=3,\n","            n_class=2,\n","            init_channel=2,\n","            kernel_size=3,\n","            pool_size=2,\n","            ap_factor=2,\n","            gpu=-1,\n","            loss_func='nn.CrossEntropyLoss'\n","        ):\n","        super(Model_L2_Sigmoid, self).__init__()\n","        self.gpu = gpu\n","        self.pool_size = pool_size\n","        self.phase = 'train'\n","        self.loss_func = eval(loss_func)()\n","\n","        self.c0=nn.Conv3d(1, init_channel, kernel_size, 1, int(kernel_size/2))\n","        self.c1=nn.Conv3d(init_channel, int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.c2=nn.Conv3d(int(init_channel * (ap_factor ** 1)), int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","        self.c3=nn.Conv3d(int(init_channel * (ap_factor ** 1)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.c4=nn.Conv3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","        self.c5=nn.Conv3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 3)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.dc0=nn.ConvTranspose3d(int(init_channel * (ap_factor ** 3)), int(init_channel * (ap_factor ** 3)), self.pool_size, self.pool_size, 0)\n","        self.dc1=nn.Conv3d(int(init_channel * (ap_factor ** 2) + init_channel * (ap_factor ** 3)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","        self.dc2=nn.Conv3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.dc3=nn.ConvTranspose3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 2)), self.pool_size, self.pool_size, 0)\n","        self.dc4=nn.Conv3d(int(init_channel * (ap_factor ** 1) + init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","        self.dc5=nn.Conv3d(int(init_channel * (ap_factor ** 1)), int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.dc6=nn.Conv3d(int(init_channel * (ap_factor ** 1)), n_class, 1, 1)\n","\n","        self.bnc0=nn.BatchNorm3d(init_channel)\n","        self.bnc1=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","\n","        self.bnc2=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","        self.bnc3=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","\n","        self.bnc4=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","        self.bnc5=nn.BatchNorm3d(int(init_channel * (ap_factor ** 3)))\n","\n","        self.bndc1=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","        self.bndc2=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","        self.bndc4=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","        self.bndc5=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","\n","        self.pool = nn.MaxPool3d(pool_size, pool_size)\n","\n","    def _calc(self, x):\n","        e0 = F.sigmoid(self.bnc0(self.c0(x)))\n","        syn0 = F.sigmoid(self.bnc1(self.c1(e0)))\n","        del e0\n","        e1 = self.pool(syn0)\n","        e2 = F.sigmoid(self.bnc2(self.c2(e1)))\n","        syn1 = F.sigmoid(self.bnc3(self.c3(e2)))\n","        del e1, e2\n","        e3 = self.pool(syn1)\n","        e4 = F.sigmoid(self.bnc4(self.c4(e3)))\n","        e5 = F.sigmoid(self.bnc5(self.c5(e4)))\n","        del e3, e4\n","        d0 = torch.cat([self.dc0(e5), syn1], dim=1)\n","        del e5, syn1\n","        d1 = F.sigmoid(self.bndc1(self.dc1(d0)))\n","        d2 = F.sigmoid(self.bndc2(self.dc2(d1)))\n","        del d0, d1\n","        d3 = torch.cat([self.dc3(d2), syn0], dim=1)\n","        del d2, syn0\n","        d4 = F.sigmoid(self.bndc4(self.dc4(d3)))\n","        d5 = F.sigmoid(self.bndc5(self.dc5(d4)))\n","        del d3, d4\n","        d6 = self.dc6(d5)\n","        del d5\n","        return d6\n","\n","    def forward(self, x, t=None, seg=True):\n","        h = self._calc(x)\n","        if seg:\n","            pred = F.softmax(h, dim=1)\n","            del h\n","            return pred\n","        else:\n","            loss = self.loss_func(h, t.float())\n","            pred = F.softmax(h, dim=1)\n","            del h\n","            return loss, pred.data\n","        \n","class Model_L2_NoResiduals(nn.Module):\n","    def __init__(\n","            self,\n","            ndim=3,\n","            n_class=2,\n","            init_channel=2,\n","            kernel_size=3,\n","            pool_size=2,\n","            ap_factor=2,\n","            gpu=-1,\n","            loss_func='nn.CrossEntropyLoss'\n","        ):\n","        super(Model_L2_NoResiduals, self).__init__()\n","        self.gpu = gpu\n","        self.pool_size = pool_size\n","        self.phase = 'train'\n","        self.loss_func = eval(loss_func)()\n","\n","        self.c0=nn.Conv3d(1, init_channel, kernel_size, 1, int(kernel_size/2))\n","        self.c1=nn.Conv3d(init_channel, int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.c2=nn.Conv3d(int(init_channel * (ap_factor ** 1)), int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","        self.c3=nn.Conv3d(int(init_channel * (ap_factor ** 1)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.c4=nn.Conv3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","        self.c5=nn.Conv3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 3)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.dc0=nn.ConvTranspose3d(int(init_channel * (ap_factor ** 3)), int(init_channel * (ap_factor ** 3)), self.pool_size, self.pool_size, 0)\n","        self.dc1=nn.Conv3d(int(init_channel * (ap_factor ** 2) + init_channel * (ap_factor ** 3)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","        self.dc2=nn.Conv3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.dc3=nn.ConvTranspose3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 2)), self.pool_size, self.pool_size, 0)\n","        self.dc4=nn.Conv3d(int(init_channel * (ap_factor ** 1) + init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","        self.dc5=nn.Conv3d(int(init_channel * (ap_factor ** 1)), int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.dc6=nn.Conv3d(int(init_channel * (ap_factor ** 1)), n_class, 1, 1)\n","\n","        self.bnc0=nn.BatchNorm3d(init_channel)\n","        self.bnc1=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","\n","        self.bnc2=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","        self.bnc3=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","\n","        self.bnc4=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","        self.bnc5=nn.BatchNorm3d(int(init_channel * (ap_factor ** 3)))\n","\n","        self.bndc1=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","        self.bndc2=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","        self.bndc4=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","        self.bndc5=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","\n","        self.pool = nn.MaxPool3d(pool_size, pool_size)\n","\n","    def _calc(self, x):\n","        e0 = F.relu(self.bnc0(self.c0(x)))\n","        syn0 = F.relu(self.bnc1(self.c1(e0)))\n","        del e0\n","        e1 = self.pool(syn0)\n","        e2 = F.relu(self.bnc2(self.c2(e1)))\n","        syn1 = F.relu(self.bnc3(self.c3(e2)))\n","        del e1, e2\n","        e3 = self.pool(syn1)\n","        e4 = F.relu(self.bnc4(self.c4(e3)))\n","        e5 = F.relu(self.bnc5(self.c5(e4)))\n","        del e3, e4\n","        d0 = torch.cat([self.dc0(e5), torch.zeros_like(syn1)], dim=1)\n","        del e5, syn1\n","        d1 = F.relu(self.bndc1(self.dc1(d0)))\n","        d2 = F.relu(self.bndc2(self.dc2(d1)))\n","        del d0, d1\n","        d3 = torch.cat([self.dc3(d2), torch.zeros_like(syn0)], dim=1)\n","        del d2, syn0\n","        d4 = F.relu(self.bndc4(self.dc4(d3)))\n","        d5 = F.relu(self.bndc5(self.dc5(d4)))\n","        del d3, d4\n","        d6 = self.dc6(d5)\n","        del d5\n","        return d6\n","\n","    def forward(self, x, t=None, seg=True):\n","        h = self._calc(x)\n","        if seg:\n","            pred = F.softmax(h, dim=1)\n","            del h\n","            return pred\n","        else:\n","            loss = self.loss_func(h, t.float())\n","            pred = F.softmax(h, dim=1)\n","            del h\n","            return loss, pred.data"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:17:31.629908Z","iopub.status.busy":"2024-04-14T12:17:31.629560Z","iopub.status.idle":"2024-04-14T12:17:31.638497Z","shell.execute_reply":"2024-04-14T12:17:31.637452Z","shell.execute_reply.started":"2024-04-14T12:17:31.629881Z"},"trusted":true},"outputs":[],"source":["def iou(y_pred: torch.Tensor, y_gt: torch.Tensor, smooth=1e-6):\n","    \"\"\"\n","    Calculate Intersection over Union (IoU) for 3D semantic segmentation masks.\n","\n","    Parameters:\n","    - outputs: a tensor of shape (N, C, D, H, W) where\n","      N is the batch size,\n","      C is the number of classes,\n","      D is the depth,\n","      H and W are the height and width of the masks.\n","      The tensor should contain binary predictions (0 or 1).\n","    - labels: a tensor of the same shape as outputs containing the ground truth masks.\n","    - smooth: a small constant added to avoid division by zero.\n","\n","    Returns:\n","    - IoU: The Intersection over Union score for each class.\n","    \"\"\"\n","    # Ensure that both outputs and labels are booleans\n","    y_pred = y_pred > 0.5\n","    y_gt = y_gt > 0.5\n","    \n","    # Intersection and Union\n","    intersection = (y_pred & y_gt).float().sum(dim=(2, 3, 4)) # Sum over the spatial dimensions\n","    union = (y_pred | y_gt).float().sum(dim=(2, 3, 4)) # Sum over the spatial dimensions\n","    \n","    # Compute the IoU and handle cases where the union is 0\n","    iou = (intersection + smooth) / (union + smooth)\n","    \n","    return torch.mean(iou)  # Return the average IoU over the batch"]},{"cell_type":"code","execution_count":14,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-04-14T12:17:32.923356Z","iopub.status.busy":"2024-04-14T12:17:32.923010Z","iopub.status.idle":"2024-04-14T12:17:36.479628Z","shell.execute_reply":"2024-04-14T12:17:36.478105Z","shell.execute_reply.started":"2024-04-14T12:17:32.923328Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2024-04-14 12:17:32,929] A new study created in memory with name: no-name-13ed868b-da00-4417-b2a3-1a49c843febc\n","/tmp/ipykernel_103/2176007645.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  lr = trial.suggest_loguniform('lr', 1e-5, 1e-3)\n","  0%|          | 0/484 [00:03<?, ?it/s]\n","[W 2024-04-14 12:17:36,310] Trial 0 failed with parameters: {'lr': 0.00027384916370804755, 'num_epochs': 67} because of the following error: KeyboardInterrupt().\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n","    value_or_values = func(trial)\n","  File \"/tmp/ipykernel_103/2176007645.py\", line 23, in objective\n","    train_loss = train_epoch()\n","  File \"/tmp/ipykernel_103/1540288744.py\", line 15, in train_epoch\n","    total_loss += loss.item()\n","KeyboardInterrupt\n","[W 2024-04-14 12:17:36,311] Trial 0 failed with value None.\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m test_loss\n\u001b[1;32m     30\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of finished trials:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(study\u001b[38;5;241m.\u001b[39mtrials))\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m'\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n","Cell \u001b[0;32mIn[14], line 23\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     22\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 23\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     25\u001b[0m     test_loss, test_iou \u001b[38;5;241m=\u001b[39m test_epoch()\n","Cell \u001b[0;32mIn[11], line 15\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     13\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 15\u001b[0m         total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m         pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["def objective(trial):\n","    # Define the hyperparameters to be tuned\n","    lr = trial.suggest_loguniform('lr', 1e-5, 1e-3)\n","#     init_channel = trial.suggest_categorical('init_channel', [2, 4, 8])\n","#     kernel_size = trial.suggest_categorical('kernel_size', [3, 5])\n","#     pool_size = trial.suggest_categorical('pool_size', [2, 3])\n","#     ap_factor = trial.suggest_categorical('ap_factor', [1, 2])\n","    num_epochs = trial.suggest_int('num_epochs', 5, 150)\n","\n","    # Model, dataset, and DataLoader setup\n","    model = Model_L2_NoResiduals(n_class=2, gpu=0)\n","    model.cuda()\n","\n","    train_set = EmbryoDataset(image_dir_path=\"/kaggle/input/dl-reprod/Images/train/Images\", gt_dir_path=\"/kaggle/input/dl-reprod/GroundTruth/train/GroundTruth_NSN\", augment=True)\n","    test_set = EmbryoDataset(image_dir_path=\"/kaggle/input/dl-reprod/Images/test/Images\", gt_dir_path=\"/kaggle/input/dl-reprod/GroundTruth/test/GroundTruth_QCANet\", augment=False)\n","    train_loader = DataLoader(train_set, batch_size=1, shuffle=True)\n","    test_loader = DataLoader(test_set, batch_size=1, shuffle=False)\n","\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        train_loss = train_epoch()\n","        model.eval()\n","        test_loss, test_iou = test_epoch()\n","\n","\n","    return test_loss\n","\n","study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=10)\n","\n","print('Number of finished trials:', len(study.trials))\n","print('Best trial:', study.best_trial.params)"]},{"cell_type":"markdown","metadata":{},"source":["## NDN Hyperparameter Tuning"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-04-14T12:17:39.258645Z","iopub.status.busy":"2024-04-14T12:17:39.258258Z","iopub.status.idle":"2024-04-14T12:17:39.298973Z","shell.execute_reply":"2024-04-14T12:17:39.297974Z","shell.execute_reply.started":"2024-04-14T12:17:39.258614Z"},"trusted":true},"outputs":[],"source":["class Model_L4(nn.Module):\n","    def __init__(\n","            self,\n","            ndim=3,\n","            n_class=2,\n","            init_channel=2,\n","            kernel_size=3,\n","            pool_size=2,\n","            ap_factor=2,\n","            gpu=-1,\n","        ):\n","        super(Model_L4, self).__init__()\n","        self.gpu = gpu\n","        self.pool_size = pool_size\n","        self.phase = 'train'\n","\n","        self.c0=nn.Conv3d(1, init_channel, kernel_size, 1, int(kernel_size/2))\n","        self.c1=nn.Conv3d(init_channel, int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","        self.c2=nn.Conv3d(int(init_channel * (ap_factor ** 1)), int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","        self.c3=nn.Conv3d(int(init_channel * (ap_factor ** 1)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.c4=nn.Conv3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","        self.c5=nn.Conv3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 3)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.c6=nn.Conv3d(int(init_channel * (ap_factor ** 3)), int(init_channel * (ap_factor ** 3)), kernel_size, 1, int(kernel_size/2))\n","        self.c7=nn.Conv3d(int(init_channel * (ap_factor ** 3)), int(init_channel * (ap_factor ** 4)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.c8=nn.Conv3d(int(init_channel * (ap_factor ** 4)), int(init_channel * (ap_factor ** 4)), kernel_size, 1, int(kernel_size/2))\n","        self.c9=nn.Conv3d(int(init_channel * (ap_factor ** 4)), int(init_channel * (ap_factor ** 5)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.dc0=nn.ConvTranspose3d(int(init_channel * (ap_factor ** 5)), int(init_channel * (ap_factor ** 5)), self.pool_size, self.pool_size, 0)\n","        self.dc1=nn.Conv3d(int(init_channel * (ap_factor ** 4) + init_channel * (ap_factor ** 5)), int(init_channel * (ap_factor ** 4)), kernel_size, 1, int(kernel_size/2))\n","        self.dc2=nn.Conv3d(int(init_channel * (ap_factor ** 4)), int(init_channel * (ap_factor ** 4)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.dc3=nn.ConvTranspose3d(int(init_channel * (ap_factor ** 4)), int(init_channel * (ap_factor ** 4)), self.pool_size, self.pool_size, 0)\n","        self.dc4=nn.Conv3d(int(init_channel * (ap_factor ** 3) + init_channel * (ap_factor ** 4)), int(init_channel * (ap_factor ** 3)), kernel_size, 1, int(kernel_size/2))\n","        self.dc5=nn.Conv3d(int(init_channel * (ap_factor ** 3)), int(init_channel * (ap_factor ** 3)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.dc6=nn.ConvTranspose3d(int(init_channel * (ap_factor ** 3)), int(init_channel * (ap_factor ** 3)), self.pool_size, self.pool_size, 0)\n","        self.dc7=nn.Conv3d(int(init_channel * (ap_factor ** 2) + init_channel * (ap_factor ** 3)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","        self.dc8=nn.Conv3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.dc9=nn.ConvTranspose3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 2)), self.pool_size, self.pool_size, 0)\n","        self.dc10=nn.Conv3d(int(init_channel * (ap_factor ** 1) + init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","        self.dc11=nn.Conv3d(int(init_channel * (ap_factor ** 1)), int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.dc12=nn.Conv3d(int(init_channel * (ap_factor ** 1)), n_class, 1, 1)\n","\n","        self.bnc0=nn.BatchNorm3d(init_channel)\n","        self.bnc1=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","\n","        self.bnc2=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","        self.bnc3=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","\n","        self.bnc4=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","        self.bnc5=nn.BatchNorm3d(int(init_channel * (ap_factor ** 3)))\n","\n","        self.bnc6=nn.BatchNorm3d(int(init_channel * (ap_factor ** 3)))\n","        self.bnc7=nn.BatchNorm3d(int(init_channel * (ap_factor ** 4)))\n","\n","        self.bnc8=nn.BatchNorm3d(int(init_channel * (ap_factor ** 4)))\n","        self.bnc9=nn.BatchNorm3d(int(init_channel * (ap_factor ** 5)))\n","        self.bndc1=nn.BatchNorm3d(int(init_channel * (ap_factor ** 4)))\n","        self.bndc2=nn.BatchNorm3d(int(init_channel * (ap_factor ** 4)))\n","        self.bndc4=nn.BatchNorm3d(int(init_channel * (ap_factor ** 3)))\n","        self.bndc5=nn.BatchNorm3d(int(init_channel * (ap_factor ** 3)))\n","        self.bndc7=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","        self.bndc8=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","        self.bndc10=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","        self.bndc11=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","\n","        self.pool = nn.MaxPool3d(pool_size, pool_size)\n","\n","    def _calc(self, x):\n","        e0 = F.relu(self.bnc0(self.c0(x)))\n","        syn0 = F.relu(self.bnc1(self.c1(e0)))\n","        del e0\n","        e1 = self.pool(syn0)\n","        e2 = F.relu(self.bnc2(self.c2(e1)))\n","        syn1 = F.relu(self.bnc3(self.c3(e2)))\n","        del e1, e2\n","        e3 = self.pool(syn1)\n","        e4 = F.relu(self.bnc4(self.c4(e3)))\n","        syn2 = F.relu(self.bnc5(self.c5(e4)))\n","        del e3, e4\n","        e5 = self.pool(syn2)\n","        e6 = F.relu(self.bnc6(self.c6(e5)))\n","        syn3 = F.relu(self.bnc7(self.c7(e6)))\n","        del e5, e6\n","        e7 = self.pool(syn3)\n","        e8 = F.relu(self.bnc8(self.c8(e7)))\n","        e9 = F.relu(self.bnc9(self.c9(e8)))\n","        del e7, e8\n","        d0 = torch.cat([self.dc0(e9), syn3], dim=1)\n","        del e9, syn3\n","        d1 = F.relu(self.bndc1(self.dc1(d0)))\n","        d2 = F.relu(self.bndc2(self.dc2(d1)))\n","        del d0, d1\n","        d3 = torch.cat([self.dc3(d2), syn2], dim=1)\n","        del d2, syn2\n","        d4 = F.relu(self.bndc4(self.dc4(d3)))\n","        d5 = F.relu(self.bndc5(self.dc5(d4)))\n","        del d3, d4\n","        d6 = torch.cat([self.dc6(d5), syn1], dim=1)\n","        del d5, syn1\n","        d7 = F.relu(self.bndc7(self.dc7(d6)))\n","        d8 = F.relu(self.bndc8(self.dc8(d7)))\n","        del d6, d7\n","        d9 = torch.cat([self.dc9(d8), syn0], dim=1)\n","        del d8, syn0\n","        d10 = F.relu(self.bndc10(self.dc10(d9)))\n","        d11 = F.relu(self.bndc11(self.dc11(d10)))\n","        del d9, d10\n","\n","        d12 = self.dc12(d11)\n","        del d11\n","        return d12\n","\n","    def forward(self, x, t=None, seg=True):\n","        h = self._calc(x)\n","        pred = F.softmax(h, dim=1)\n","        del h\n","        return pred"]},{"cell_type":"code","execution_count":16,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-04-14T12:17:40.411836Z","iopub.status.busy":"2024-04-14T12:17:40.411468Z","iopub.status.idle":"2024-04-14T12:17:42.392697Z","shell.execute_reply":"2024-04-14T12:17:42.391034Z","shell.execute_reply.started":"2024-04-14T12:17:40.411810Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2024-04-14 12:17:40,418] A new study created in memory with name: no-name-ffd54f88-e1e3-46b8-a886-5f76cbcbd478\n","/tmp/ipykernel_103/294003187.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n","  lr = trial.suggest_loguniform('lr', 1e-5, 1e-3)\n","  0%|          | 0/484 [00:01<?, ?it/s]\n","[W 2024-04-14 12:17:41,950] Trial 0 failed with parameters: {'lr': 0.000846484066828721, 'num_epochs': 77} because of the following error: KeyboardInterrupt().\n","Traceback (most recent call last):\n","  File \"/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n","    value_or_values = func(trial)\n","  File \"/tmp/ipykernel_103/294003187.py\", line 22, in objective\n","    train_loss = train_epoch()\n","  File \"/tmp/ipykernel_103/1540288744.py\", line 6, in train_epoch\n","    for i, data in enumerate(train_loader):\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 630, in __next__\n","    data = self._next_data()\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 674, in _next_data\n","    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n","    data = [self.dataset[idx] for idx in possibly_batched_index]\n","  File \"/tmp/ipykernel_103/3110573473.py\", line 66, in __getitem__\n","    y = self.__preprocess(gt_raw, type=1)\n","  File \"/tmp/ipykernel_103/3110573473.py\", line 39, in __preprocess\n","    preprocessed = zoom(preprocessed, (2.1875, x_scale_factor, y_scale_factor), order=3)\n","  File \"/opt/conda/lib/python3.10/site-packages/scipy/ndimage/_interpolation.py\", line 869, in zoom\n","    _nd_image.zoom_shift(filtered, zoom, None, output, order, mode, cval, npad,\n","KeyboardInterrupt\n","[W 2024-04-14 12:17:41,953] Trial 0 failed with value None.\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m test_loss\n\u001b[1;32m     29\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of finished trials:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(study\u001b[38;5;241m.\u001b[39mtrials))\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m'\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n","Cell \u001b[0;32mIn[16], line 22\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     21\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 22\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     24\u001b[0m     test_loss, test_iou \u001b[38;5;241m=\u001b[39m test_epoch()\n","Cell \u001b[0;32mIn[11], line 6\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_set)) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m      7\u001b[0m         x, y \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m      8\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[4], line 66\u001b[0m, in \u001b[0;36mEmbryoDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     63\u001b[0m gt_raw \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mimread(curr_gt_path)\n\u001b[1;32m     65\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__preprocess(image_raw, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 66\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__preprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgt_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_augment:\n\u001b[1;32m     69\u001b[0m     transform_type \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m4\u001b[39m\n","Cell \u001b[0;32mIn[4], line 39\u001b[0m, in \u001b[0;36mEmbryoDataset.__preprocess\u001b[0;34m(self, raw, type)\u001b[0m\n\u001b[1;32m     37\u001b[0m x_scale_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m \u001b[38;5;241m/\u001b[39m x\n\u001b[1;32m     38\u001b[0m y_scale_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m \u001b[38;5;241m/\u001b[39m y\n\u001b[0;32m---> 39\u001b[0m preprocessed \u001b[38;5;241m=\u001b[39m \u001b[43mzoom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2.1875\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_scale_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_scale_factor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m preprocessed \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(preprocessed)\n\u001b[1;32m     42\u001b[0m preprocessed \u001b[38;5;241m=\u001b[39m preprocessed\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scipy/ndimage/_interpolation.py:869\u001b[0m, in \u001b[0;36mzoom\u001b[0;34m(input, zoom, output, order, mode, cval, prefilter, grid_mode)\u001b[0m\n\u001b[1;32m    865\u001b[0m zoom \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mdivide(zoom_nominator, zoom_div,\n\u001b[1;32m    866\u001b[0m                     out\u001b[38;5;241m=\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mones_like(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mfloat64),\n\u001b[1;32m    867\u001b[0m                     where\u001b[38;5;241m=\u001b[39mzoom_div \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    868\u001b[0m zoom \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mascontiguousarray(zoom)\n\u001b[0;32m--> 869\u001b[0m \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzoom_shift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzoom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnpad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mgrid_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["def objective(trial):\n","    # Define the hyperparameters to be tuned\n","    lr = trial.suggest_loguniform('lr', 1e-5, 1e-3)\n","#     init_channel = trial.suggest_categorical('init_channel', [2, 4, 8])\n","#     kernel_size = trial.suggest_categorical('kernel_size', [3, 5])\n","#     pool_size = trial.suggest_categorical('pool_size', [2, 3])\n","#     ap_factor = trial.suggest_categorical('ap_factor', [1, 2])\n","    num_epochs = trial.suggest_int('num_epochs', 5, 150)\n","\n","    # Model, dataset, and DataLoader setup\n","    model = Model_L4(n_class=1, gpu=1)\n","    model.cuda()\n","\n","    train_set = EmbryoDataset(image_dir_path=\"/kaggle/input/dl-reprod/Images/train/Images\", gt_dir_path=\"/kaggle/input/dl-reprod/GroundTruth/train/GroundTruth_NDN\", augment=True)\n","    test_set = EmbryoDataset(image_dir_path=\"/kaggle/input/dl-reprod/Images/test/Images\", gt_dir_path=\"/kaggle/input/dl-reprod/GroundTruth/test/GroundTruth_QCANet\", augment=False)\n","    train_loader = DataLoader(train_set, batch_size=1, shuffle=True)\n","    test_loader = DataLoader(test_set, batch_size=1, shuffle=False)\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        train_loss = train_epoch()\n","        model.eval()\n","        test_loss, test_iou = test_epoch()\n","\n","\n","    return test_loss\n","\n","study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=10)\n","\n","print('Number of finished trials:', len(study.trials))\n","print('Best trial:', study.best_trial.params)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4635605,"sourceId":7894709,"sourceType":"datasetVersion"},{"datasetId":4666593,"sourceId":7937918,"sourceType":"datasetVersion"},{"datasetId":4715431,"sourceId":8006387,"sourceType":"datasetVersion"},{"datasetId":4763184,"sourceId":8072219,"sourceType":"datasetVersion"},{"modelInstanceId":19907,"sourceId":23800,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
