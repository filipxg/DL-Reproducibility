{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T14:58:38.824545Z","iopub.status.busy":"2024-04-08T14:58:38.823843Z","iopub.status.idle":"2024-04-08T14:58:58.722928Z","shell.execute_reply":"2024-04-08T14:58:58.721739Z","shell.execute_reply.started":"2024-04-08T14:58:38.824513Z"},"trusted":true},"outputs":[],"source":["!pip install chainer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T14:59:02.916417Z","iopub.status.busy":"2024-04-08T14:59:02.916059Z","iopub.status.idle":"2024-04-08T14:59:08.707349Z","shell.execute_reply":"2024-04-08T14:59:08.706493Z","shell.execute_reply.started":"2024-04-08T14:59:02.916387Z"},"trusted":true},"outputs":[],"source":["import os\n","import sys\n","sys.path.insert(1, \"/kaggle/input/qcanet3/QCANet\")\n","import numpy as np\n","from skimage import io\n","import src.tools.qca_net"]},{"cell_type":"markdown","metadata":{},"source":["<h3> Everything below is ported from original QCANet Chainer-based code </h3>"]},{"cell_type":"markdown","metadata":{},"source":["<h1> NSN inference </h1>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T15:03:27.775755Z","iopub.status.busy":"2024-04-08T15:03:27.775213Z","iopub.status.idle":"2024-04-08T15:03:37.403801Z","shell.execute_reply":"2024-04-08T15:03:37.402920Z","shell.execute_reply.started":"2024-04-08T15:03:27.775727Z"},"trusted":true},"outputs":[],"source":["import os\n","import copy\n","import chainer\n","from chainer import cuda\n","\n","from skimage import transform as tr\n","from src.lib.utils import mirror_extension_image\n","from src.lib.model import Model_L2, Model_L4\n","from os import listdir\n","\n","\n","patchsize = [128,128,128]\n","stride = [64,64,64]\n","resolution = [1.0,1.0,2.18]\n","scaling = True\n","ndim = 3\n","\n","image_folder_dir = \"/kaggle/input/dl-reprod/Images/test/Images/\" #path to test images\n","learned_model = \"/kaggle/input/qcanet3/QCANet/models/learned_nsn.npz\" # path to learned model\n","\n","## create model \n","class_weight = np.array([1, 1]).astype(np.float32)\n","nsn = Model_L2(class_weight=class_weight, n_class=2, init_channel=16,\n","                   kernel_size=3, pool_size=2, ap_factor=2, gpu=1)\n","chainer.serializers.load_npz(learned_model, nsn, strict=False)\n","cuda.get_device_from_id(0).use()  # Make a specified GPU current\n","nsn.to_gpu()  # Copy the SegmentNucleus model to the GPU\n","model = nsn\n","\n","\n","for test_images in os.listdir(image_folder_dir):\n","    image_path = image_folder_dir + test_images\n","\n","    image = io.imread(image_path)\n","    im_size = image.shape\n","    if ndim == 2:\n","        ip_size = (int(image.shape[0] * resolution[1]), int(image.shape[1] * resolution[0]))\n","        sh = [int(stride[0]/2), int(stride[1]/2)]\n","    elif ndim == 3:\n","        ip_size = (int(image.shape[0] * resolution[2]), int(image.shape[1] * resolution[1]), int(image.shape[2] * resolution[0]))\n","        sh = [int(stride[0]/2), int(stride[1]/2), int(stride[2]/2)]\n","\n","\n","    ip_size = (int(image.shape[0] * resolution[2]), int(image.shape[1] * resolution[1]), int(image.shape[2] * resolution[0]))\n","    sh = [int(stride[0]/2), int(stride[1]/2), int(stride[2]/2)]\n","\n","    image = tr.resize(image, ip_size, order = 1, preserve_range = True)\n","    im_size_ip = image.shape\n","\n","    if scaling:\n","        image = image.astype(np.float32)\n","        image = (image - image.min()) / (image.max() - image.min())\n","\n","    ''' calculation for pad size'''\n","    if np.min(patchsize) > np.max(np.array(im_size) + np.array(sh)*2):\n","        if ndim == 2:\n","            pad_size = [patchsize[0], patchsize[1]]\n","        elif ndim == 3:\n","            pad_size = [patchsize[0], patchsize[1], patchsize[2]]\n","    else:\n","        pad_size = []\n","        for axis in range(len(im_size_ip)):\n","            if (im_size_ip[axis] + 2*sh[axis] - patchsize[axis]) % stride[axis] == 0:\n","                stride_num = int((im_size_ip[axis] + 2*sh[axis] - patchsize[axis]) / stride[axis])\n","            else:\n","                stride_num = int((im_size_ip[axis] + 2*sh[axis] - patchsize[axis]) / stride[axis]) + 1\n","            pad_size.append(int(stride[axis] * stride_num + patchsize[axis]))\n","\n","    pre_img = np.zeros(pad_size)\n","\n","    if ndim == 2:\n","        image = mirror_extension_image(image=image, ndim=ndim, length=int(np.max(patchsize)))[patchsize[0]-sh[0]:patchsize[0]-sh[0]+pad_size[0], patchsize[1]-sh[1]:patchsize[1]-sh[1]+pad_size[1]]\n","        for y in range(0, pad_size[0]-stride[0], stride[0]):\n","            for x in range(0, pad_size[1]-stride[1], stride[1]):\n","                x_patch = image[y:y+patchsize[0], x:x+patchsize[1]]\n","                x_patch = np.expand_dims(np.expand_dims(x_patch.astype(np.float32), axis=0), axis=0)\n","    #             if self.gpu >= 0:\n","    #                 x_patch = cuda.to_gpu(x_patch)\n","                s_output = model(x=x_patch, t=None, seg=True)\n","    #             if self.gpu >= 0:\n","    #                 s_output = cuda.to_cpu(s_output)\n","                pred = copy.deepcopy((0 < (s_output[0][1] - s_output[0][0])) * 255)\n","                # Add segmentation image\n","                pre_img[y:y+stride[0], x:x+stride[1]] += pred[sh[0]:-sh[0], sh[1]:-sh[1]]\n","        seg_img = (pre_img > 0) * 255\n","        seg_img = seg_img[:im_size_ip[0], :im_size_ip[1]]\n","    elif ndim == 3:\n","        image = mirror_extension_image(image=image, ndim=ndim, length=int(np.max(patchsize)))[patchsize[0]-sh[0]:patchsize[0]-sh[0]+pad_size[0], patchsize[1]-sh[1]:patchsize[1]-sh[1]+pad_size[1], patchsize[2]-sh[2]:patchsize[2]-sh[2]+pad_size[2]]\n","        for z in range(0, pad_size[0]-stride[0], stride[0]):\n","            for y in range(0, pad_size[1]-stride[1], stride[1]):\n","                for x in range(0, pad_size[2]-stride[2], stride[2]):\n","                    x_patch = image[z:z+patchsize[0], y:y+patchsize[1], x:x+patchsize[2]]\n","                    x_patch = np.expand_dims(np.expand_dims(x_patch.astype(np.float32), axis=0), axis=0)\n","                    x_patch = cuda.to_gpu(x_patch)\n","                    s_output = model(x=x_patch, t=None, seg=True)\n","                    s_output = cuda.to_cpu(s_output)\n","                    pred = copy.deepcopy((0 < (s_output[0][1] - s_output[0][0])) * 255)\n","                    # Add segmentation image\n","                    pre_img[z:z+stride[0], y:y+stride[1], x:x+stride[2]] += pred[sh[0]:-sh[0], sh[1]:-sh[1], sh[2]:-sh[2]]\n","        seg_img = (pre_img > 0) * 255\n","        seg_img = seg_img[:im_size_ip[0], :im_size_ip[1], :im_size_ip[2]]\n","    seg_img = (tr.resize(seg_img, im_size, order = 1, preserve_range = True) > 0) * 255\n","\n","filename = f\"nsn/nsn_{test_images}\"\n","io.imsave(filename, seg_img.astype(np.uint8))\n"]},{"cell_type":"markdown","metadata":{},"source":["<h1> NDN inference </h1>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import copy\n","import chainer\n","from chainer import cuda\n","\n","from skimage import transform as tr\n","from src.lib.utils import mirror_extension_image\n","from src.lib.model import Model_L2, Model_L4\n","from os import listdir\n","\n","\n","patchsize = [128,128,128]\n","stride = [64,64,64]\n","resolution = [1.0,1.0,2.18]\n","scaling = True\n","ndim = 3\n","\n","image_folder_dir = \"/kaggle/input/dl-reprod/Images/test/Images/\" #path to test images\n","learned_model = \"/kaggle/input/qcanet3/QCANet/models/learned_ndn.npz\" # path to learned model\n","\n","## create model \n","ndn = Model_L4(class_weight=class_weight, n_class=2, init_channel=12,\n","                   kernel_size=5, pool_size=2, ap_factor=2, gpu=1)\n","chainer.serializers.load_npz(learned_model, ndn, strict=False)\n","cuda.get_device_from_id(0).use()  # Make a specified GPU current\n","ndn.to_gpu()  # Copy the SegmentNucleus model to the GPU\n","model = ndn\n","\n","for test_images in os.listdir(image_folder_dir):\n","    image_path = image_folder_dir + test_images\n","\n","    image = io.imread(image_path)\n","    im_size = image.shape\n","    if ndim == 2:\n","        ip_size = (int(image.shape[0] * resolution[1]), int(image.shape[1] * resolution[0]))\n","        sh = [int(stride[0]/2), int(stride[1]/2)]\n","    elif ndim == 3:\n","        ip_size = (int(image.shape[0] * resolution[2]), int(image.shape[1] * resolution[1]), int(image.shape[2] * resolution[0]))\n","        sh = [int(stride[0]/2), int(stride[1]/2), int(stride[2]/2)]\n","\n","\n","    ip_size = (int(image.shape[0] * resolution[2]), int(image.shape[1] * resolution[1]), int(image.shape[2] * resolution[0]))\n","    sh = [int(stride[0]/2), int(stride[1]/2), int(stride[2]/2)]\n","\n","    image = tr.resize(image, ip_size, order = 1, preserve_range = True)\n","    im_size_ip = image.shape\n","\n","    if scaling:\n","        image = image.astype(np.float32)\n","        image = (image - image.min()) / (image.max() - image.min())\n","\n","    ''' calculation for pad size'''\n","    if np.min(patchsize) > np.max(np.array(im_size) + np.array(sh)*2):\n","        if ndim == 2:\n","            pad_size = [patchsize[0], patchsize[1]]\n","        elif ndim == 3:\n","            pad_size = [patchsize[0], patchsize[1], patchsize[2]]\n","    else:\n","        pad_size = []\n","        for axis in range(len(im_size_ip)):\n","            if (im_size_ip[axis] + 2*sh[axis] - patchsize[axis]) % stride[axis] == 0:\n","                stride_num = int((im_size_ip[axis] + 2*sh[axis] - patchsize[axis]) / stride[axis])\n","            else:\n","                stride_num = int((im_size_ip[axis] + 2*sh[axis] - patchsize[axis]) / stride[axis]) + 1\n","            pad_size.append(int(stride[axis] * stride_num + patchsize[axis]))\n","\n","    pre_img = np.zeros(pad_size)\n","\n","    if ndim == 2:\n","        image = mirror_extension_image(image=image, ndim=ndim, length=int(np.max(patchsize)))[patchsize[0]-sh[0]:patchsize[0]-sh[0]+pad_size[0], patchsize[1]-sh[1]:patchsize[1]-sh[1]+pad_size[1]]\n","        for y in range(0, pad_size[0]-stride[0], stride[0]):\n","            for x in range(0, pad_size[1]-stride[1], stride[1]):\n","                x_patch = image[y:y+patchsize[0], x:x+patchsize[1]]\n","                x_patch = np.expand_dims(np.expand_dims(x_patch.astype(np.float32), axis=0), axis=0)\n","    #             if self.gpu >= 0:\n","    #                 x_patch = cuda.to_gpu(x_patch)\n","                s_output = model(x=x_patch, t=None, seg=True)\n","    #             if self.gpu >= 0:\n","    #                 s_output = cuda.to_cpu(s_output)\n","                pred = copy.deepcopy((0 < (s_output[0][1] - s_output[0][0])) * 255)\n","                # Add segmentation image\n","                pre_img[y:y+stride[0], x:x+stride[1]] += pred[sh[0]:-sh[0], sh[1]:-sh[1]]\n","        seg_img = (pre_img > 0) * 255\n","        seg_img = seg_img[:im_size_ip[0], :im_size_ip[1]]\n","    elif ndim == 3:\n","        image = mirror_extension_image(image=image, ndim=ndim, length=int(np.max(patchsize)))[patchsize[0]-sh[0]:patchsize[0]-sh[0]+pad_size[0], patchsize[1]-sh[1]:patchsize[1]-sh[1]+pad_size[1], patchsize[2]-sh[2]:patchsize[2]-sh[2]+pad_size[2]]\n","        for z in range(0, pad_size[0]-stride[0], stride[0]):\n","            for y in range(0, pad_size[1]-stride[1], stride[1]):\n","                for x in range(0, pad_size[2]-stride[2], stride[2]):\n","                    x_patch = image[z:z+patchsize[0], y:y+patchsize[1], x:x+patchsize[2]]\n","                    x_patch = np.expand_dims(np.expand_dims(x_patch.astype(np.float32), axis=0), axis=0)\n","                    x_patch = cuda.to_gpu(x_patch)\n","                    s_output = model(x=x_patch, t=None, seg=True)\n","                    s_output = cuda.to_cpu(s_output)\n","                    pred = copy.deepcopy((0 < (s_output[0][1] - s_output[0][0])) * 255)\n","                    # Add segmentation image\n","                    pre_img[z:z+stride[0], y:y+stride[1], x:x+stride[2]] += pred[sh[0]:-sh[0], sh[1]:-sh[1], sh[2]:-sh[2]]\n","        seg_img = (pre_img > 0) * 255\n","        seg_img = seg_img[:im_size_ip[0], :im_size_ip[1], :im_size_ip[2]]\n","    seg_img = (tr.resize(seg_img, im_size, order = 1, preserve_range = True) > 0) * 255\n","filename = f\"ndn/ndn_{test_images}\"\n","io.imsave(filename, seg_img.astype(np.uint8))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T18:16:06.858425Z","iopub.status.busy":"2024-04-07T18:16:06.858020Z","iopub.status.idle":"2024-04-07T18:16:08.042095Z","shell.execute_reply":"2024-04-07T18:16:08.041108Z","shell.execute_reply.started":"2024-04-07T18:16:06.858399Z"},"trusted":true},"outputs":[],"source":["!zip -r /kaggle/working/zips/ndn.zip /kaggle/working/ndn -i \\*.tif"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4635605,"sourceId":7894709,"sourceType":"datasetVersion"},{"datasetId":4666689,"sourceId":7938041,"sourceType":"datasetVersion"},{"datasetId":4713635,"sourceId":8003886,"sourceType":"datasetVersion"},{"datasetId":4713933,"sourceId":8004307,"sourceType":"datasetVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
