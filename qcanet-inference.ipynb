{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T14:58:38.824545Z","iopub.status.busy":"2024-04-08T14:58:38.823843Z","iopub.status.idle":"2024-04-08T14:58:58.722928Z","shell.execute_reply":"2024-04-08T14:58:58.721739Z","shell.execute_reply.started":"2024-04-08T14:58:38.824513Z"},"trusted":true},"outputs":[],"source":["!pip install chainer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T14:59:02.916417Z","iopub.status.busy":"2024-04-08T14:59:02.916059Z","iopub.status.idle":"2024-04-08T14:59:08.707349Z","shell.execute_reply":"2024-04-08T14:59:08.706493Z","shell.execute_reply.started":"2024-04-08T14:59:02.916387Z"},"trusted":true},"outputs":[],"source":["import os\n","import sys\n","sys.path.insert(1, \"/kaggle/input/qcanet3/QCANet\")\n","import numpy as np\n","from skimage import io\n","import src.tools.qca_net"]},{"cell_type":"markdown","metadata":{},"source":["<h3> Everything below is ported from original QCANet Chainer-based code </h3>"]},{"cell_type":"markdown","metadata":{},"source":["<h1> NSN inference </h1>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T15:03:27.775755Z","iopub.status.busy":"2024-04-08T15:03:27.775213Z","iopub.status.idle":"2024-04-08T15:03:37.403801Z","shell.execute_reply":"2024-04-08T15:03:37.402920Z","shell.execute_reply.started":"2024-04-08T15:03:27.775727Z"},"trusted":true},"outputs":[],"source":["import os\n","import copy\n","import chainer\n","from chainer import cuda\n","\n","from skimage import transform as tr\n","from src.lib.utils import mirror_extension_image\n","from src.lib.model import Model_L2, Model_L4\n","from os import listdir\n","\n","\n","patchsize = [128,128,128]\n","stride = [64,64,64]\n","resolution = [1.0,1.0,2.18]\n","scaling = True\n","ndim = 3\n","\n","## create model \n","class_weight = np.array([1, 1]).astype(np.float32)\n","nsn = Model_L2(class_weight=class_weight, n_class=2, init_channel=16,\n","                   kernel_size=3, pool_size=2, ap_factor=2, gpu=1)\n","chainer.serializers.load_npz(\"/kaggle/input/qcanet3/QCANet/models/learned_nsn.npz\", nsn, strict=False)\n","cuda.get_device_from_id(0).use()  # Make a specified GPU current\n","nsn.to_gpu()  # Copy the SegmentNucleus model to the GPU\n","model = nsn\n","# ndn = Model_L4(class_weight=class_weight, n_class=2, init_channel=12,\n","#                    kernel_size=5, pool_size=2, ap_factor=2, gpu=1)\n","# chainer.serializers.load_npz(\"/kaggle/input/qcanet3/QCANet/models/learned_ndn.npz\", ndn, strict=False)\n","# cuda.get_device_from_id(0).use()  # Make a specified GPU current\n","# ndn.to_gpu()  # Copy the SegmentNucleus model to the GPU\n","# model = ndn\n","\n","segbase = 'SegmentationImages'\n","# if not (pt.exists(self.opbase + self.psep + segbase)):\n","#     os.mkdir(self.opbase + self.psep + segbase)\n","\n","folder_dir = \"/kaggle/input/dl-reprod/Images/test/Images/\"\n","\n","# for test_images in os.listdir(folder_dir):\n","image_path = \"/kaggle/input/dl-reprod/Images/test/Images/Emb1_t351.tif\"\n","\n","image = io.imread(image_path)\n","im_size = image.shape\n","if ndim == 2:\n","    ip_size = (int(image.shape[0] * resolution[1]), int(image.shape[1] * resolution[0]))\n","    sh = [int(stride[0]/2), int(stride[1]/2)]\n","elif ndim == 3:\n","    ip_size = (int(image.shape[0] * resolution[2]), int(image.shape[1] * resolution[1]), int(image.shape[2] * resolution[0]))\n","    sh = [int(stride[0]/2), int(stride[1]/2), int(stride[2]/2)]\n","\n","\n","ip_size = (int(image.shape[0] * resolution[2]), int(image.shape[1] * resolution[1]), int(image.shape[2] * resolution[0]))\n","sh = [int(stride[0]/2), int(stride[1]/2), int(stride[2]/2)]\n","\n","image = tr.resize(image, ip_size, order = 1, preserve_range = True)\n","im_size_ip = image.shape\n","\n","#added in myself\n","if scaling:\n","    image = image.astype(np.float32)\n","    image = (image - image.min()) / (image.max() - image.min())\n","\n","''' calculation for pad size'''\n","if np.min(patchsize) > np.max(np.array(im_size) + np.array(sh)*2):\n","    if ndim == 2:\n","        pad_size = [patchsize[0], patchsize[1]]\n","    elif ndim == 3:\n","        pad_size = [patchsize[0], patchsize[1], patchsize[2]]\n","else:\n","    pad_size = []\n","    for axis in range(len(im_size_ip)):\n","        if (im_size_ip[axis] + 2*sh[axis] - patchsize[axis]) % stride[axis] == 0:\n","            stride_num = int((im_size_ip[axis] + 2*sh[axis] - patchsize[axis]) / stride[axis])\n","        else:\n","            stride_num = int((im_size_ip[axis] + 2*sh[axis] - patchsize[axis]) / stride[axis]) + 1\n","        pad_size.append(int(stride[axis] * stride_num + patchsize[axis]))\n","\n","pre_img = np.zeros(pad_size)\n","\n","if ndim == 2:\n","    image = mirror_extension_image(image=image, ndim=ndim, length=int(np.max(patchsize)))[patchsize[0]-sh[0]:patchsize[0]-sh[0]+pad_size[0], patchsize[1]-sh[1]:patchsize[1]-sh[1]+pad_size[1]]\n","    for y in range(0, pad_size[0]-stride[0], stride[0]):\n","        for x in range(0, pad_size[1]-stride[1], stride[1]):\n","            x_patch = image[y:y+patchsize[0], x:x+patchsize[1]]\n","            x_patch = np.expand_dims(np.expand_dims(x_patch.astype(np.float32), axis=0), axis=0)\n","#             if self.gpu >= 0:\n","#                 x_patch = cuda.to_gpu(x_patch)\n","            s_output = model(x=x_patch, t=None, seg=True)\n","#             if self.gpu >= 0:\n","#                 s_output = cuda.to_cpu(s_output)\n","            pred = copy.deepcopy((0 < (s_output[0][1] - s_output[0][0])) * 255)\n","            # Add segmentation image\n","            pre_img[y:y+stride[0], x:x+stride[1]] += pred[sh[0]:-sh[0], sh[1]:-sh[1]]\n","    seg_img = (pre_img > 0) * 255\n","    seg_img = seg_img[:im_size_ip[0], :im_size_ip[1]]\n","elif ndim == 3:\n","    image = mirror_extension_image(image=image, ndim=ndim, length=int(np.max(patchsize)))[patchsize[0]-sh[0]:patchsize[0]-sh[0]+pad_size[0], patchsize[1]-sh[1]:patchsize[1]-sh[1]+pad_size[1], patchsize[2]-sh[2]:patchsize[2]-sh[2]+pad_size[2]]\n","    for z in range(0, pad_size[0]-stride[0], stride[0]):\n","        for y in range(0, pad_size[1]-stride[1], stride[1]):\n","            for x in range(0, pad_size[2]-stride[2], stride[2]):\n","                x_patch = image[z:z+patchsize[0], y:y+patchsize[1], x:x+patchsize[2]]\n","                x_patch = np.expand_dims(np.expand_dims(x_patch.astype(np.float32), axis=0), axis=0)\n","                x_patch = cuda.to_gpu(x_patch)\n","                s_output = model(x=x_patch, t=None, seg=True)\n","                s_output = cuda.to_cpu(s_output)\n","                pred = copy.deepcopy((0 < (s_output[0][1] - s_output[0][0])) * 255)\n","                # Add segmentation image\n","                pre_img[z:z+stride[0], y:y+stride[1], x:x+stride[2]] += pred[sh[0]:-sh[0], sh[1]:-sh[1], sh[2]:-sh[2]]\n","    seg_img = (pre_img > 0) * 255\n","    seg_img = seg_img[:im_size_ip[0], :im_size_ip[1], :im_size_ip[2]]\n","seg_img_nsn = (tr.resize(seg_img, im_size, order = 1, preserve_range = True) > 0) * 255\n","# filename = os.path.join(self.opbase, segbase, os.path.basename(image_path)[:os.path.basename(image_path).rfind('.')] + '.tif')\n","#filename = self.opbase + self.psep + segbase + self.psep + 'segimg_t{0:03d}.tif'.format(int(image_path[image_path.rfind('/')+1:image_path.rfind('.')]))\n","# filename = f\"nsn/ndn_{test_images}\"\n","# io.imsave(filename, seg_img.astype(np.uint8))\n","#     print(seg_img.astype(np.uint16))"]},{"cell_type":"markdown","metadata":{},"source":["<h1> NDN inference </h1>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import copy\n","import chainer\n","from chainer import cuda\n","\n","from skimage import transform as tr\n","from src.lib.utils import mirror_extension_image\n","from src.lib.model import Model_L2, Model_L4\n","from os import listdir\n","\n","\n","patchsize = [128,128,128]\n","stride = [64,64,64]\n","resolution = [1.0,1.0,2.18]\n","scaling = True\n","ndim = 3\n","\n","## create model \n","ndn = Model_L4(class_weight=class_weight, n_class=2, init_channel=12,\n","                   kernel_size=5, pool_size=2, ap_factor=2, gpu=1)\n","chainer.serializers.load_npz(\"/kaggle/input/qcanet3/QCANet/models/learned_ndn.npz\", ndn, strict=False)\n","cuda.get_device_from_id(0).use()  # Make a specified GPU current\n","ndn.to_gpu()  # Copy the SegmentNucleus model to the GPU\n","model = ndn\n","\n","segbase = 'SegmentationImages'\n","# if not (pt.exists(self.opbase + self.psep + segbase)):\n","#     os.mkdir(self.opbase + self.psep + segbase)\n","\n","folder_dir = \"/kaggle/input/dl-reprod/Images/test/Images/\"\n","\n","# for test_images in os.listdir(folder_dir):\n","image_path = \"/kaggle/input/dl-reprod/Images/test/Images/Emb1_t351.tif\"\n","\n","image = io.imread(image_path)\n","im_size = image.shape\n","if ndim == 2:\n","    ip_size = (int(image.shape[0] * resolution[1]), int(image.shape[1] * resolution[0]))\n","    sh = [int(stride[0]/2), int(stride[1]/2)]\n","elif ndim == 3:\n","    ip_size = (int(image.shape[0] * resolution[2]), int(image.shape[1] * resolution[1]), int(image.shape[2] * resolution[0]))\n","    sh = [int(stride[0]/2), int(stride[1]/2), int(stride[2]/2)]\n","\n","\n","ip_size = (int(image.shape[0] * resolution[2]), int(image.shape[1] * resolution[1]), int(image.shape[2] * resolution[0]))\n","sh = [int(stride[0]/2), int(stride[1]/2), int(stride[2]/2)]\n","\n","image = tr.resize(image, ip_size, order = 1, preserve_range = True)\n","im_size_ip = image.shape\n","\n","#added in myself\n","if scaling:\n","    image = image.astype(np.float32)\n","    image = (image - image.min()) / (image.max() - image.min())\n","\n","''' calculation for pad size'''\n","if np.min(patchsize) > np.max(np.array(im_size) + np.array(sh)*2):\n","    if ndim == 2:\n","        pad_size = [patchsize[0], patchsize[1]]\n","    elif ndim == 3:\n","        pad_size = [patchsize[0], patchsize[1], patchsize[2]]\n","else:\n","    pad_size = []\n","    for axis in range(len(im_size_ip)):\n","        if (im_size_ip[axis] + 2*sh[axis] - patchsize[axis]) % stride[axis] == 0:\n","            stride_num = int((im_size_ip[axis] + 2*sh[axis] - patchsize[axis]) / stride[axis])\n","        else:\n","            stride_num = int((im_size_ip[axis] + 2*sh[axis] - patchsize[axis]) / stride[axis]) + 1\n","        pad_size.append(int(stride[axis] * stride_num + patchsize[axis]))\n","\n","pre_img = np.zeros(pad_size)\n","\n","if ndim == 2:\n","    image = mirror_extension_image(image=image, ndim=ndim, length=int(np.max(patchsize)))[patchsize[0]-sh[0]:patchsize[0]-sh[0]+pad_size[0], patchsize[1]-sh[1]:patchsize[1]-sh[1]+pad_size[1]]\n","    for y in range(0, pad_size[0]-stride[0], stride[0]):\n","        for x in range(0, pad_size[1]-stride[1], stride[1]):\n","            x_patch = image[y:y+patchsize[0], x:x+patchsize[1]]\n","            x_patch = np.expand_dims(np.expand_dims(x_patch.astype(np.float32), axis=0), axis=0)\n","#             if self.gpu >= 0:\n","#                 x_patch = cuda.to_gpu(x_patch)\n","            s_output = model(x=x_patch, t=None, seg=True)\n","#             if self.gpu >= 0:\n","#                 s_output = cuda.to_cpu(s_output)\n","            pred = copy.deepcopy((0 < (s_output[0][1] - s_output[0][0])) * 255)\n","            # Add segmentation image\n","            pre_img[y:y+stride[0], x:x+stride[1]] += pred[sh[0]:-sh[0], sh[1]:-sh[1]]\n","    seg_img = (pre_img > 0) * 255\n","    seg_img = seg_img[:im_size_ip[0], :im_size_ip[1]]\n","elif ndim == 3:\n","    image = mirror_extension_image(image=image, ndim=ndim, length=int(np.max(patchsize)))[patchsize[0]-sh[0]:patchsize[0]-sh[0]+pad_size[0], patchsize[1]-sh[1]:patchsize[1]-sh[1]+pad_size[1], patchsize[2]-sh[2]:patchsize[2]-sh[2]+pad_size[2]]\n","    for z in range(0, pad_size[0]-stride[0], stride[0]):\n","        for y in range(0, pad_size[1]-stride[1], stride[1]):\n","            for x in range(0, pad_size[2]-stride[2], stride[2]):\n","                x_patch = image[z:z+patchsize[0], y:y+patchsize[1], x:x+patchsize[2]]\n","                x_patch = np.expand_dims(np.expand_dims(x_patch.astype(np.float32), axis=0), axis=0)\n","                x_patch = cuda.to_gpu(x_patch)\n","                s_output = model(x=x_patch, t=None, seg=True)\n","                s_output = cuda.to_cpu(s_output)\n","                pred = copy.deepcopy((0 < (s_output[0][1] - s_output[0][0])) * 255)\n","                # Add segmentation image\n","                pre_img[z:z+stride[0], y:y+stride[1], x:x+stride[2]] += pred[sh[0]:-sh[0], sh[1]:-sh[1], sh[2]:-sh[2]]\n","    seg_img = (pre_img > 0) * 255\n","    seg_img = seg_img[:im_size_ip[0], :im_size_ip[1], :im_size_ip[2]]\n","seg_img_nsn = (tr.resize(seg_img, im_size, order = 1, preserve_range = True) > 0) * 255\n","# filename = os.path.join(self.opbase, segbase, os.path.basename(image_path)[:os.path.basename(image_path).rfind('.')] + '.tif')\n","#filename = self.opbase + self.psep + segbase + self.psep + 'segimg_t{0:03d}.tif'.format(int(image_path[image_path.rfind('/')+1:image_path.rfind('.')]))\n","# filename = f\"nsn/ndn_{test_images}\"\n","# io.imsave(filename, seg_img.astype(np.uint8))\n","#     print(seg_img.astype(np.uint16))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T18:16:06.858425Z","iopub.status.busy":"2024-04-07T18:16:06.858020Z","iopub.status.idle":"2024-04-07T18:16:08.042095Z","shell.execute_reply":"2024-04-07T18:16:08.041108Z","shell.execute_reply.started":"2024-04-07T18:16:06.858399Z"},"trusted":true},"outputs":[],"source":["!zip -r /kaggle/working/zips/ndn.zip /kaggle/working/ndn -i \\*.tif"]},{"cell_type":"markdown","metadata":{},"source":["<h1> Watershed post-processing </h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-08T15:06:44.610469Z","iopub.status.busy":"2024-04-08T15:06:44.609573Z","iopub.status.idle":"2024-04-08T15:06:44.764244Z","shell.execute_reply":"2024-04-08T15:06:44.763174Z","shell.execute_reply.started":"2024-04-08T15:06:44.610435Z"},"trusted":true},"outputs":[],"source":["from scipy import ndimage\n","from skimage.segmentation import watershed\n","\n","seg_img = seg_img_nsn\n","\n","### Detection Phase ###\n","det_img = seg_img_ndn\n","\n","### Post-Processing ###\n","if det_img.sum() > 0:\n","    distance = ndimage.distance_transform_edt(seg_img)\n","    wsimage = watershed(-distance, det_img, mask=seg_img)\n","else:\n","    wsimage = morphology.label(seg_img, neighbors=4)\n","labels = np.unique(wsimage)\n","wsimage = np.searchsorted(labels, wsimage)\n","# filename = os.path.join(opbase, wsbase, os.path.basename(image_path)[:os.path.basename(image_path).rfind('.')] + '.tif')\n","# filename = opbase + psep + wsbase + psep + 'ws_t{0:03d}.tif'.format(int(image_path[image_path.rfind('/')+1:image_path.rfind('.')]))\n","io.imsave(\"wsimage_try.tif\", wsimage.astype(np.uint16))"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4635605,"sourceId":7894709,"sourceType":"datasetVersion"},{"datasetId":4666689,"sourceId":7938041,"sourceType":"datasetVersion"},{"datasetId":4713635,"sourceId":8003886,"sourceType":"datasetVersion"},{"datasetId":4713933,"sourceId":8004307,"sourceType":"datasetVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
