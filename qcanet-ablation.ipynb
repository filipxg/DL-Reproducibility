{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T16:18:32.094005Z","iopub.status.busy":"2024-04-11T16:18:32.093561Z","iopub.status.idle":"2024-04-11T16:18:32.105223Z","shell.execute_reply":"2024-04-11T16:18:32.104381Z","shell.execute_reply.started":"2024-04-11T16:18:32.093978Z"},"trusted":true},"outputs":[],"source":["import os\n","import sys\n","sys.path.insert(1, \"/kaggle/input/3d-unet\")\n","# sys.path.insert(1, \"/kaggle/input/qcanet-pytorch/QCANet\")"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-11T16:20:00.550470Z","iopub.status.busy":"2024-04-11T16:20:00.550091Z","iopub.status.idle":"2024-04-11T16:20:04.563384Z","shell.execute_reply":"2024-04-11T16:20:04.562545Z","shell.execute_reply.started":"2024-04-11T16:20:00.550442Z"},"trusted":true},"outputs":[],"source":["import torch\n","import cv2\n","import numpy as np\n","from skimage import io\n","from pytorch3dunet.unet3d.model import UNet3D\n","# from src.lib.model import Model_L2, Model_L4"]},{"cell_type":"markdown","metadata":{},"source":["<h1> Ablation studies </h1>\n","\n","<p> Below are 3 variants of the QCANet NSN model. The first one is the baseline, the second one has the ReLU activation function replaced with the Sigmoid activation function, and the third one has residual connections between the convolutional and deconvolutional layers removed. </p>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T17:29:35.010063Z","iopub.status.busy":"2024-04-11T17:29:35.009676Z","iopub.status.idle":"2024-04-11T17:29:35.080462Z","shell.execute_reply":"2024-04-11T17:29:35.079427Z","shell.execute_reply.started":"2024-04-11T17:29:35.010030Z"},"trusted":true},"outputs":[],"source":["from torch import nn\n","\n","class Model_L2(nn.Module):\n","    def __init__(\n","            self,\n","            ndim=3,\n","            n_class=2,\n","            init_channel=2,\n","            kernel_size=3,\n","            pool_size=2,\n","            ap_factor=2,\n","            gpu=-1,\n","            loss_func='nn.CrossEntropyLoss'\n","        ):\n","        super(Model_L2, self).__init__()\n","        self.gpu = gpu\n","        self.pool_size = pool_size\n","        self.phase = 'train'\n","        self.loss_func = eval(loss_func)()\n","\n","        self.c0=nn.Conv3d(1, init_channel, kernel_size, 1, int(kernel_size/2))\n","        self.c1=nn.Conv3d(init_channel, int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.c2=nn.Conv3d(int(init_channel * (ap_factor ** 1)), int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","        self.c3=nn.Conv3d(int(init_channel * (ap_factor ** 1)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.c4=nn.Conv3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","        self.c5=nn.Conv3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 3)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.dc0=nn.ConvTranspose3d(int(init_channel * (ap_factor ** 3)), int(init_channel * (ap_factor ** 3)), self.pool_size, self.pool_size, 0)\n","        self.dc1=nn.Conv3d(int(init_channel * (ap_factor ** 2) + init_channel * (ap_factor ** 3)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","        self.dc2=nn.Conv3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.dc3=nn.ConvTranspose3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 2)), self.pool_size, self.pool_size, 0)\n","        self.dc4=nn.Conv3d(int(init_channel * (ap_factor ** 1) + init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","        self.dc5=nn.Conv3d(int(init_channel * (ap_factor ** 1)), int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.dc6=nn.Conv3d(int(init_channel * (ap_factor ** 1)), n_class, 1, 1)\n","\n","        self.bnc0=nn.BatchNorm3d(init_channel)\n","        self.bnc1=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","\n","        self.bnc2=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","        self.bnc3=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","\n","        self.bnc4=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","        self.bnc5=nn.BatchNorm3d(int(init_channel * (ap_factor ** 3)))\n","\n","        self.bndc1=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","        self.bndc2=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","        self.bndc4=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","        self.bndc5=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","\n","        self.pool = nn.MaxPool3d(pool_size, pool_size)\n","\n","    def _calc(self, x):\n","        e0 = F.relu(self.bnc0(self.c0(x)))\n","        syn0 = F.relu(self.bnc1(self.c1(e0)))\n","        del e0\n","        e1 = self.pool(syn0)\n","        e2 = F.relu(self.bnc2(self.c2(e1)))\n","        syn1 = F.relu(self.bnc3(self.c3(e2)))\n","        del e1, e2\n","        e3 = self.pool(syn1)\n","        e4 = F.relu(self.bnc4(self.c4(e3)))\n","        e5 = F.relu(self.bnc5(self.c5(e4)))\n","        del e3, e4\n","        d0 = torch.cat([self.dc0(e5), syn1], dim=1)\n","        del e5, syn1\n","        d1 = F.relu(self.bndc1(self.dc1(d0)))\n","        d2 = F.relu(self.bndc2(self.dc2(d1)))\n","        del d0, d1\n","        d3 = torch.cat([self.dc3(d2), syn0], dim=1)\n","        del d2, syn0\n","        d4 = F.relu(self.bndc4(self.dc4(d3)))\n","        d5 = F.relu(self.bndc5(self.dc5(d4)))\n","        del d3, d4\n","        d6 = self.dc6(d5)\n","        del d5\n","        return d6\n","\n","    def forward(self, x, t=None, seg=True):\n","        h = self._calc(x)\n","        if seg:\n","            pred = F.softmax(h, dim=1)\n","            del h\n","            return pred\n","        else:\n","            loss = self.loss_func(h, t.float())\n","            pred = F.softmax(h, dim=1)\n","            del h\n","            return loss, pred.data\n","        \n","class Model_L2_Sigmoid(nn.Module):\n","    def __init__(\n","            self,\n","            ndim=3,\n","            n_class=2,\n","            init_channel=2,\n","            kernel_size=3,\n","            pool_size=2,\n","            ap_factor=2,\n","            gpu=-1,\n","            loss_func='nn.CrossEntropyLoss'\n","        ):\n","        super(Model_L2_Sigmoid, self).__init__()\n","        self.gpu = gpu\n","        self.pool_size = pool_size\n","        self.phase = 'train'\n","        self.loss_func = eval(loss_func)()\n","\n","        self.c0=nn.Conv3d(1, init_channel, kernel_size, 1, int(kernel_size/2))\n","        self.c1=nn.Conv3d(init_channel, int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.c2=nn.Conv3d(int(init_channel * (ap_factor ** 1)), int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","        self.c3=nn.Conv3d(int(init_channel * (ap_factor ** 1)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.c4=nn.Conv3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","        self.c5=nn.Conv3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 3)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.dc0=nn.ConvTranspose3d(int(init_channel * (ap_factor ** 3)), int(init_channel * (ap_factor ** 3)), self.pool_size, self.pool_size, 0)\n","        self.dc1=nn.Conv3d(int(init_channel * (ap_factor ** 2) + init_channel * (ap_factor ** 3)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","        self.dc2=nn.Conv3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.dc3=nn.ConvTranspose3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 2)), self.pool_size, self.pool_size, 0)\n","        self.dc4=nn.Conv3d(int(init_channel * (ap_factor ** 1) + init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","        self.dc5=nn.Conv3d(int(init_channel * (ap_factor ** 1)), int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.dc6=nn.Conv3d(int(init_channel * (ap_factor ** 1)), n_class, 1, 1)\n","\n","        self.bnc0=nn.BatchNorm3d(init_channel)\n","        self.bnc1=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","\n","        self.bnc2=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","        self.bnc3=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","\n","        self.bnc4=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","        self.bnc5=nn.BatchNorm3d(int(init_channel * (ap_factor ** 3)))\n","\n","        self.bndc1=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","        self.bndc2=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","        self.bndc4=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","        self.bndc5=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","\n","        self.pool = nn.MaxPool3d(pool_size, pool_size)\n","\n","    def _calc(self, x):\n","        e0 = F.sigmoid(self.bnc0(self.c0(x)))\n","        syn0 = F.sigmoid(self.bnc1(self.c1(e0)))\n","        del e0\n","        e1 = self.pool(syn0)\n","        e2 = F.sigmoid(self.bnc2(self.c2(e1)))\n","        syn1 = F.sigmoid(self.bnc3(self.c3(e2)))\n","        del e1, e2\n","        e3 = self.pool(syn1)\n","        e4 = F.sigmoid(self.bnc4(self.c4(e3)))\n","        e5 = F.sigmoid(self.bnc5(self.c5(e4)))\n","        del e3, e4\n","        d0 = torch.cat([self.dc0(e5), syn1], dim=1)\n","        del e5, syn1\n","        d1 = F.sigmoid(self.bndc1(self.dc1(d0)))\n","        d2 = F.sigmoid(self.bndc2(self.dc2(d1)))\n","        del d0, d1\n","        d3 = torch.cat([self.dc3(d2), syn0], dim=1)\n","        del d2, syn0\n","        d4 = F.sigmoid(self.bndc4(self.dc4(d3)))\n","        d5 = F.sigmoid(self.bndc5(self.dc5(d4)))\n","        del d3, d4\n","        d6 = self.dc6(d5)\n","        del d5\n","        return d6\n","\n","    def forward(self, x, t=None, seg=True):\n","        h = self._calc(x)\n","        if seg:\n","            pred = F.softmax(h, dim=1)\n","            del h\n","            return pred\n","        else:\n","            loss = self.loss_func(h, t.float())\n","            pred = F.softmax(h, dim=1)\n","            del h\n","            return loss, pred.data\n","        \n","class Model_L2_NoResiduals(nn.Module):\n","    def __init__(\n","            self,\n","            ndim=3,\n","            n_class=2,\n","            init_channel=2,\n","            kernel_size=3,\n","            pool_size=2,\n","            ap_factor=2,\n","            gpu=-1,\n","            loss_func='nn.CrossEntropyLoss'\n","        ):\n","        super(Model_L2_NoResiduals, self).__init__()\n","        self.gpu = gpu\n","        self.pool_size = pool_size\n","        self.phase = 'train'\n","        self.loss_func = eval(loss_func)()\n","\n","        self.c0=nn.Conv3d(1, init_channel, kernel_size, 1, int(kernel_size/2))\n","        self.c1=nn.Conv3d(init_channel, int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.c2=nn.Conv3d(int(init_channel * (ap_factor ** 1)), int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","        self.c3=nn.Conv3d(int(init_channel * (ap_factor ** 1)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.c4=nn.Conv3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","        self.c5=nn.Conv3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 3)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.dc0=nn.ConvTranspose3d(int(init_channel * (ap_factor ** 3)), int(init_channel * (ap_factor ** 3)), self.pool_size, self.pool_size, 0)\n","        self.dc1=nn.Conv3d(int(init_channel * (ap_factor ** 2) + init_channel * (ap_factor ** 3)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","        self.dc2=nn.Conv3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 2)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.dc3=nn.ConvTranspose3d(int(init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 2)), self.pool_size, self.pool_size, 0)\n","        self.dc4=nn.Conv3d(int(init_channel * (ap_factor ** 1) + init_channel * (ap_factor ** 2)), int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","        self.dc5=nn.Conv3d(int(init_channel * (ap_factor ** 1)), int(init_channel * (ap_factor ** 1)), kernel_size, 1, int(kernel_size/2))\n","\n","        self.dc6=nn.Conv3d(int(init_channel * (ap_factor ** 1)), n_class, 1, 1)\n","\n","        self.bnc0=nn.BatchNorm3d(init_channel)\n","        self.bnc1=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","\n","        self.bnc2=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","        self.bnc3=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","\n","        self.bnc4=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","        self.bnc5=nn.BatchNorm3d(int(init_channel * (ap_factor ** 3)))\n","\n","        self.bndc1=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","        self.bndc2=nn.BatchNorm3d(int(init_channel * (ap_factor ** 2)))\n","        self.bndc4=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","        self.bndc5=nn.BatchNorm3d(int(init_channel * (ap_factor ** 1)))\n","\n","        self.pool = nn.MaxPool3d(pool_size, pool_size)\n","\n","    def _calc(self, x):\n","        e0 = F.relu(self.bnc0(self.c0(x)))\n","        syn0 = F.relu(self.bnc1(self.c1(e0)))\n","        del e0\n","        e1 = self.pool(syn0)\n","        e2 = F.relu(self.bnc2(self.c2(e1)))\n","        syn1 = F.relu(self.bnc3(self.c3(e2)))\n","        del e1, e2\n","        e3 = self.pool(syn1)\n","        e4 = F.relu(self.bnc4(self.c4(e3)))\n","        e5 = F.relu(self.bnc5(self.c5(e4)))\n","        del e3, e4\n","        # All-zeros vector instead of syn1 used in the concatenation to\n","        # remove the information from the earlier layers\n","        d0 = torch.cat([self.dc0(e5), torch.zeros_like(syn1)], dim=1)\n","        del e5, syn1\n","        d1 = F.relu(self.bndc1(self.dc1(d0)))\n","        d2 = F.relu(self.bndc2(self.dc2(d1)))\n","        del d0, d1\n","        d3 = torch.cat([self.dc3(d2), torch.zeros_like(syn0)], dim=1)\n","        del d2, syn0\n","        d4 = F.relu(self.bndc4(self.dc4(d3)))\n","        d5 = F.relu(self.bndc5(self.dc5(d4)))\n","        del d3, d4\n","        d6 = self.dc6(d5)\n","        del d5\n","        return d6\n","\n","    def forward(self, x, t=None, seg=True):\n","        h = self._calc(x)\n","        if seg:\n","            pred = F.softmax(h, dim=1)\n","            del h\n","            return pred\n","        else:\n","            loss = self.loss_func(h, t.float())\n","            pred = F.softmax(h, dim=1)\n","            del h\n","            return loss, pred.data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T16:55:04.850034Z","iopub.status.busy":"2024-04-11T16:55:04.849135Z","iopub.status.idle":"2024-04-11T16:55:04.855360Z","shell.execute_reply":"2024-04-11T16:55:04.854525Z","shell.execute_reply.started":"2024-04-11T16:55:04.849999Z"},"trusted":true},"outputs":[],"source":["def separate_channels(mask: torch.tensor) -> torch.tensor:\n","    class_labels = [0,1]\n","    gt = torch.zeros((len(class_labels), mask.shape[1], mask.shape[2], mask.shape[3]))\n","    \n","    for class_label in class_labels:\n","        gt[class_label] = torch.where(mask == class_label, 1, 0)\n","        \n","    return gt"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T16:37:53.196525Z","iopub.status.busy":"2024-04-11T16:37:53.196163Z","iopub.status.idle":"2024-04-11T16:37:53.213041Z","shell.execute_reply":"2024-04-11T16:37:53.212076Z","shell.execute_reply.started":"2024-04-11T16:37:53.196497Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from scipy.ndimage import zoom\n","import cv2\n","import torch.nn.functional as F\n","\n","class EmbryoDataset(Dataset):\n","    \n","    def __init__(self, image_dir_path: str, gt_dir_path: str, augment: bool = False):\n","        self.image_dir_path = image_dir_path\n","        self.gt_dir_path = gt_dir_path\n","        self._filenames = os.listdir(image_dir_path)\n","        self._augment = augment\n","        \n","        if self._augment:\n","            self._filenames = self._filenames * 4\n","        \n","    def __len__(self):\n","        return len(self._filenames)\n","    \n","    def __preprocess_image(self, image: torch.Tensor) -> torch.Tensor:\n","        min_value = torch.min(image)\n","        max_value = torch.max(image)\n","        \n","        image = (image - min_value) / (max_value - min_value)\n","        \n","        return image\n","    \n","    def __preprocess_gt(self, gt: torch.Tensor) -> torch.Tensor:\n","        gt = separate_channels(gt)\n","        \n","        return gt\n","    \n","    def __preprocess(self, raw: np.ndarray, type: int) -> np.ndarray:\n","        preprocessed = raw.astype(np.float32)\n","        x, y = preprocessed.shape[1], preprocessed.shape[2]\n","        x_scale_factor = 128 / x\n","        y_scale_factor = 128 / y\n","        preprocessed = zoom(preprocessed, (2.1875, x_scale_factor, y_scale_factor), order=3)\n","        \n","        preprocessed = torch.from_numpy(preprocessed)\n","        preprocessed = preprocessed.to(\"cuda\", dtype=torch.float32)\n","        preprocessed = preprocessed.unsqueeze(dim=0)\n","        \n","        if type == 0:\n","            preprocessed = self.__preprocess_image(preprocessed)\n","        if type == 1:\n","            preprocessed = self.__preprocess_gt(preprocessed)\n","            \n","        return preprocessed\n","\n","    def __getitem__(self, idx):\n","        if self._augment:\n","            original_idx = idx // 4\n","        else:\n","            original_idx = idx\n","\n","        curr_filename = self._filenames[original_idx]\n","        curr_image_path = os.path.join(self.image_dir_path, curr_filename)\n","        curr_gt_path = os.path.join(self.gt_dir_path, curr_filename)\n","\n","        image_raw = io.imread(curr_image_path)\n","        gt_raw = io.imread(curr_gt_path)\n","        \n","        x = self.__preprocess(image_raw, type=0)\n","        y = self.__preprocess(gt_raw, type=1)\n","\n","        if self._augment:\n","            transform_type = idx % 4\n","        \n","            # Apply the specific transformation\n","            if transform_type == 1:  # Flip horizontally\n","                x = transforms.functional.hflip(x)\n","                y = transforms.functional.hflip(y)\n","            elif transform_type == 2:  # Flip vertically\n","                x = transforms.functional.vflip(x)\n","                y = transforms.functional.vflip(y)\n","            elif transform_type == 3:  # Flip both horizontally and vertically\n","                x = transforms.functional.hflip(x)\n","                y = transforms.functional.hflip(y)\n","        \n","        return (x.cuda(), y.cuda())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T16:33:52.596337Z","iopub.status.busy":"2024-04-11T16:33:52.595496Z","iopub.status.idle":"2024-04-11T16:33:52.606136Z","shell.execute_reply":"2024-04-11T16:33:52.605197Z","shell.execute_reply.started":"2024-04-11T16:33:52.596303Z"},"trusted":true},"outputs":[],"source":["train_set = EmbryoDataset(image_dir_path=\"/kaggle/input/dl-reprod/Images/train/Images\", gt_dir_path=\"/kaggle/input/dl-reprod/GroundTruth/train/GroundTruth_NSN\", augment=True)\n","test_set = EmbryoDataset(image_dir_path=\"/kaggle/input/dl-reprod/Images/test/Images\", gt_dir_path=\"/kaggle/input/dl-reprod/GroundTruth/test/GroundTruth_QCANet\", augment=False)\n","train_loader = DataLoader(train_set, batch_size=1, shuffle=True)\n","test_loader = DataLoader(test_set, batch_size=1, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T16:33:54.356369Z","iopub.status.busy":"2024-04-11T16:33:54.355516Z","iopub.status.idle":"2024-04-11T16:33:54.361499Z","shell.execute_reply":"2024-04-11T16:33:54.360517Z","shell.execute_reply.started":"2024-04-11T16:33:54.356336Z"},"trusted":true},"outputs":[],"source":["def dice_loss(input, target):\n","    # Flatten the tensors to make sure you can sum over all voxels\n","    input_flat = input.view(-1)\n","    target_flat = target.view(-1)\n","    \n","    intersection = 2.0 * (input_flat * target_flat).sum()\n","    denominator = input_flat.pow(2).sum() + target_flat.pow(2).sum()\n","    \n","    dice_score = intersection / denominator.clamp(min=1e-6)\n","    return 1 - dice_score"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T16:33:54.945483Z","iopub.status.busy":"2024-04-11T16:33:54.945096Z","iopub.status.idle":"2024-04-11T16:33:54.952565Z","shell.execute_reply":"2024-04-11T16:33:54.951499Z","shell.execute_reply.started":"2024-04-11T16:33:54.945451Z"},"trusted":true},"outputs":[],"source":["def iou(y_pred: torch.Tensor, y_gt: torch.Tensor, smooth=1e-6):\n","    \"\"\"\n","    Calculate Intersection over Union (IoU) for 3D semantic segmentation masks.\n","\n","    Parameters:\n","    - outputs: a tensor of shape (N, C, D, H, W) where\n","      N is the batch size,\n","      C is the number of classes,\n","      D is the depth,\n","      H and W are the height and width of the masks.\n","      The tensor should contain binary predictions (0 or 1).\n","    - labels: a tensor of the same shape as outputs containing the ground truth masks.\n","    - smooth: a small constant added to avoid division by zero.\n","\n","    Returns:\n","    - IoU: The Intersection over Union score for each class.\n","    \"\"\"\n","    # Ensure that both outputs and labels are booleans\n","    y_pred = y_pred > 0.5\n","    y_gt = y_gt > 0.5\n","    \n","    # Intersection and Union\n","    intersection = (y_pred & y_gt).float().sum(dim=(2, 3, 4)) # Sum over the spatial dimensions\n","    union = (y_pred | y_gt).float().sum(dim=(2, 3, 4)) # Sum over the spatial dimensions\n","    \n","    # Compute the IoU and handle cases where the union is 0\n","    iou = (intersection + smooth) / (union + smooth)\n","    \n","    return torch.mean(iou)  # Return the average IoU over the batch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T17:29:50.205373Z","iopub.status.busy":"2024-04-11T17:29:50.204674Z","iopub.status.idle":"2024-04-11T17:29:50.217608Z","shell.execute_reply":"2024-04-11T17:29:50.216706Z","shell.execute_reply.started":"2024-04-11T17:29:50.205337Z"},"trusted":true},"outputs":[],"source":["model = Model_L2(n_class=2, gpu=0)\n","# model = Model_L2_Sigmoid(n_class=2, gpu=0)\n","# model = Model_L2_NoResiduals(n_class=2, gpu=0)\n","model.cuda()\n","optimizer = torch.optim.Adam(model.parameters(), lr=5e-05)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T16:34:02.218393Z","iopub.status.busy":"2024-04-11T16:34:02.217487Z","iopub.status.idle":"2024-04-11T16:34:02.225249Z","shell.execute_reply":"2024-04-11T16:34:02.224130Z","shell.execute_reply.started":"2024-04-11T16:34:02.218345Z"},"trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","\n","def train_epoch():\n","    total_loss = 0\n","    with tqdm(total=len(train_set)) as pbar:\n","        for i, data in enumerate(train_loader):\n","            x, y = data\n","            optimizer.zero_grad()\n","            y_pred = model.forward(x)\n","            # loss, y_pred = model.forward(x, t=y, seg=False)\n","            loss = dice_loss(y_pred, y)\n","            loss.backward()\n","            optimizer.step()\n","            \n","            total_loss += loss.item()\n","            pbar.update(1)\n","    return total_loss / len(train_loader)"]},{"cell_type":"markdown","metadata":{},"source":["<p> Each model variant was trained for 10 epochs to see how the training loss behaves. </p>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-11T16:34:04.186408Z","iopub.status.busy":"2024-04-11T16:34:04.185592Z","iopub.status.idle":"2024-04-11T16:34:05.886202Z","shell.execute_reply":"2024-04-11T16:34:05.884981Z","shell.execute_reply.started":"2024-04-11T16:34:04.186380Z"},"trusted":true},"outputs":[],"source":["losses = []\n","maxloss = 1\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_loss = train_epoch()\n","    print(f'Epoch {epoch+1}/{num_epochs}, Train loss: {train_loss}')"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4635605,"sourceId":7894709,"sourceType":"datasetVersion"},{"datasetId":4666593,"sourceId":7937918,"sourceType":"datasetVersion"},{"datasetId":4715431,"sourceId":8006387,"sourceType":"datasetVersion"},{"datasetId":4763184,"sourceId":8072219,"sourceType":"datasetVersion"},{"isSourceIdPinned":true,"modelInstanceId":19907,"sourceId":23800,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30664,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
