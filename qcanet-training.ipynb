{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-09T09:04:43.438294Z","iopub.status.busy":"2024-04-09T09:04:43.437912Z","iopub.status.idle":"2024-04-09T09:05:02.381829Z","shell.execute_reply":"2024-04-09T09:05:02.380590Z","shell.execute_reply.started":"2024-04-09T09:04:43.438265Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting chainer\n","  Downloading chainer-7.8.1.tar.gz (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from chainer) (69.0.3)\n","Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from chainer) (4.9.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from chainer) (3.13.1)\n","Requirement already satisfied: numpy>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from chainer) (1.26.4)\n","Requirement already satisfied: protobuf>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from chainer) (3.20.3)\n","Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from chainer) (1.16.0)\n","Building wheels for collected packages: chainer\n","  Building wheel for chainer (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for chainer: filename=chainer-7.8.1-py3-none-any.whl size=971824 sha256=23000afc75219ffc06e9370d997f9d1d517ffb9105daf0d1ead45069d27a5921\n","  Stored in directory: /root/.cache/pip/wheels/c4/95/6a/16014db6f761c4e742755b64aac60dbe142da1df6c5919f790\n","Successfully built chainer\n","Installing collected packages: chainer\n","Successfully installed chainer-7.8.1\n"]}],"source":["!pip install chainer"]},{"cell_type":"markdown","metadata":{},"source":["<p> The chainer import warns that the cupy version might be incompatible, but installing the stated cupy version leads to other conflicts down the line. Installing all the packages from the QCANet requirements.txt does not help either because it fails with errors. Some of the package versions are so old that they're no longer available. </p>"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-09T09:05:45.628402Z","iopub.status.busy":"2024-04-09T09:05:45.627509Z","iopub.status.idle":"2024-04-09T09:05:50.729934Z","shell.execute_reply":"2024-04-09T09:05:50.728953Z","shell.execute_reply.started":"2024-04-09T09:05:45.628368Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/chainer/_environment_check.py:72: UserWarning: \n","--------------------------------------------------------------------------------\n","CuPy (cupy) version 13.0.0 may not be compatible with this version of Chainer.\n","Please consider installing the supported version by running:\n","  $ pip install 'cupy>=7.7.0,<8.0.0'\n","\n","See the following page for more details:\n","  https://docs.cupy.dev/en/latest/install.html\n","--------------------------------------------------------------------------------\n","\n","  warnings.warn(msg.format(\n"]}],"source":["import chainer\n","from chainer import cuda\n","\n","import csv\n","import sys\n","sys.path.insert(1, \"/kaggle/input/qcanet3/QCANet\")\n","import time\n","import random\n","import copy\n","import math\n","import os\n","import numpy as np\n","import argparse\n","import configparser\n","\n","sys.path.append(os.getcwd())\n","from src.lib.trainer import NSNTrainer, NDNTrainer\n","from src.lib.utils import createOpbase\n","from src.lib.utils import create_dataset_parser, create_model_parser, create_runtime_parser\n","from src.lib.utils import print_args\n","from src.lib.utils import get_dataset, get_model"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-09T09:05:53.989865Z","iopub.status.busy":"2024-04-09T09:05:53.988779Z","iopub.status.idle":"2024-04-09T09:05:55.746846Z","shell.execute_reply":"2024-04-09T09:05:55.745908Z","shell.execute_reply.started":"2024-04-09T09:05:53.989829Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<src.lib.model.Model_L4 at 0x7bd7b3341d80>"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["from src.lib.model import Model_L4\n","class_weight = np.array([1, 1]).astype(np.float32)\n","ndn = Model_L4(class_weight=class_weight, n_class=2, init_channel=12,\n","                   kernel_size=5, pool_size=2, ap_factor=2, gpu=0)\n","cuda.get_device_from_id(0).use()  # Make a specified GPU current\n","ndn.to_gpu()  # Copy the SegmentNucleus model to the GPU"]},{"cell_type":"markdown","metadata":{},"source":["<p> Usually people let their dataset classes handle their test-train split for them, but for some reason, the authors of QCANet ask for separate text files that contain the filenames of the training images and testing images respectively. I was not able to get it to find the right text files on Kaggle because it got confused with the relative paths.</p>"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-09T09:17:38.751624Z","iopub.status.busy":"2024-04-09T09:17:38.750949Z","iopub.status.idle":"2024-04-09T09:17:38.808985Z","shell.execute_reply":"2024-04-09T09:17:38.807635Z","shell.execute_reply.started":"2024-04-09T09:17:38.751595Z"},"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'train_split.txt'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreprocessedDataset\n\u001b[0;32m----> 2\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mPreprocessedDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/qcanet-dataset/qcanet-dataset/images\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_split.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNDN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43marr_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtif\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m PreprocessedDataset(\n\u001b[1;32m     10\u001b[0m     root_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/qcanet-dataset/qcanet-dataset/images\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     split_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_split.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNDN\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m train_iterator \u001b[38;5;241m=\u001b[39m chainer\u001b[38;5;241m.\u001b[39miterators\u001b[38;5;241m.\u001b[39mSerialIterator(\n\u001b[1;32m     16\u001b[0m     train_dataset, \u001b[38;5;241m1\u001b[39m, repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     17\u001b[0m )\n","File \u001b[0;32m/kaggle/input/qcanet3/QCANet/src/lib/dataset.py:197\u001b[0m, in \u001b[0;36mPreprocessedDataset.__init__\u001b[0;34m(self, root_path, split_list, train, model, arr_type, normalization, augmentation, scaling, resolution, crop_size, ndim)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain \u001b[38;5;241m=\u001b[39m train\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m=\u001b[39m ndim\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_path \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39msplit()\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_split.txt'"]}],"source":["from src.lib.dataset import PreprocessedDataset\n","train_dataset = PreprocessedDataset(\n","    root_path=\"/kaggle/input/qcanet-dataset/qcanet-dataset/images\",\n","    split_list=\"/kaggle/input/qcanet-dataset/qcanet-dataset/train_split.txt\",\n","    train=True,\n","    model='NDN',\n","    arr_type='tif'\n",")\n","test_dataset = PreprocessedDataset(\n","    root_path=\"/kaggle/input/qcanet-dataset/qcanet-dataset/images\",\n","    split_list=\"/kaggle/input/qcanet-dataset/qcanet-dataset/test_split.txt\",\n","    train=False,\n","    model='NDN'\n",")\n","train_iterator = chainer.iterators.SerialIterator(\n","    train_dataset, 1, repeat=True, shuffle=True\n",")\n","test_iterator = chainer.iterators.SerialIterator(\n","    test_dataset, 1, repeat=True, shuffle=False\n",")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-09T09:05:59.408572Z","iopub.status.busy":"2024-04-09T09:05:59.408166Z","iopub.status.idle":"2024-04-09T09:05:59.416749Z","shell.execute_reply":"2024-04-09T09:05:59.415711Z","shell.execute_reply.started":"2024-04-09T09:05:59.408543Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Output Directory not exist! Create...\n","Output Directory: /kaggle/working_Apr9Tue_2024_090559\n"]}],"source":["from src.lib.utils import createOpbase\n","opbase = createOpbase(\"/kaggle/working\")\n","with open('/kaggle/working/TestResult.csv', 'w') as f:\n","    c = csv.writer(f)\n","    c.writerow(['Epoch', 'Accuracy', 'Recall', 'Precision', 'Specificity', 'F-measure', 'IoU'])\n","with open('/kaggle/working/TrainResult.csv', 'w') as f:\n","    c = csv.writer(f)\n","    c.writerow(['Epoch', 'Accuracy', 'Recall', 'Precision', 'Specificity', 'F-measure', 'IoU'])"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-09T09:06:01.650590Z","iopub.status.busy":"2024-04-09T09:06:01.650250Z","iopub.status.idle":"2024-04-09T09:06:01.656027Z","shell.execute_reply":"2024-04-09T09:06:01.654985Z","shell.execute_reply.started":"2024-04-09T09:06:01.650564Z"},"trusted":true},"outputs":[],"source":["trainer = NDNTrainer(\n","    model=ndn,\n","    epoch=1,\n","    patchsize=(128, 128, 128),\n","    batchsize=1,\n","    gpu=0,\n","    opbase=opbase,\n",")"]},{"cell_type":"markdown","metadata":{},"source":["<p> The experiment ended here because it always struggled to find at least one of the text files with the filenames. For the files that it did find, it would throw errors related to the input dimensions of the layer, which is weird because the PreprocessedDataset class was supposed to take care of that. Other times, it would throw an error because somewhere in the training loop, they used a function which is now deprecated in the current version of skimage. Downgrading to their version of skimage broke other things. Also, certain Kaggle GPUs caused errors, something about CUDA instruction sets. </p>"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-09T09:06:02.575126Z","iopub.status.busy":"2024-04-09T09:06:02.574344Z","iopub.status.idle":"2024-04-09T09:15:19.299478Z","shell.execute_reply":"2024-04-09T09:15:19.297888Z","shell.execute_reply.started":"2024-04-09T09:06:02.575093Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[epoch 1]\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/chainer/functions/connection/convolution_nd.py:174: PerformanceWarning: The best algo of conv fwd might not be selected due to lack of workspace size (8388608)\n","  cuda.cudnn.convolution_forward(\n"]},{"ename":"FileNotFoundError","evalue":"No such file: '/kaggle/input/qcanet-dataset/qcanet-dataset/images/images_raw/train_split.txt'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_eval, test_eval, best_score \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_iterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/kaggle/input/qcanet3/QCANet/src/lib/trainer.py:409\u001b[0m, in \u001b[0;36mNDNTrainer.training\u001b[0;34m(self, iterators)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[epoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch))\n\u001b[0;32m--> 409\u001b[0m     traeval, train_sum_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_ndn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m     train_eval[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_sum_loss \u001b[38;5;241m/\u001b[39m (N_train \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatchsize))\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_epoch:\n","File \u001b[0;32m/kaggle/input/qcanet3/QCANet/src/lib/trainer.py:505\u001b[0m, in \u001b[0;36mNDNTrainer._trainer\u001b[0;34m(self, dataset_iter, opt_ndn, epoch)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N):\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;66;03m#n = perm[num]\u001b[39;00m\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         x_patch, y_patch \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_iter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    507\u001b[0m         x_patch, y_patch \u001b[38;5;241m=\u001b[39m dataset_iter\u001b[38;5;241m.\u001b[39mnext()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_image, dataset_iter\u001b[38;5;241m.\u001b[39mnext()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/chainer/iterators/serial_iterator.py:77\u001b[0m, in \u001b[0;36mSerialIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m batch \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[index] \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m indices]\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/chainer/iterators/serial_iterator.py:77\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m batch \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m indices]\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/chainer/dataset/dataset_mixin.py:67\u001b[0m, in \u001b[0;36mDatasetMixin.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_example(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m index]\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/kaggle/input/qcanet3/QCANet/src/lib/dataset.py:260\u001b[0m, in \u001b[0;36mPreprocessedDataset.get_example\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    258\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_label_2d(i)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 260\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_image_3d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_label_3d(i)\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/kaggle/input/qcanet3/QCANet/src/lib/dataset.py:230\u001b[0m, in \u001b[0;36mPreprocessedDataset._get_image_3d\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_image_3d\u001b[39m(\u001b[38;5;28mself\u001b[39m, i):\n\u001b[0;32m--> 230\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mread_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimages_raw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_path\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marr_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     ip_size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m(image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolution[\u001b[38;5;241m2\u001b[39m]), \u001b[38;5;28mint\u001b[39m(image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolution[\u001b[38;5;241m1\u001b[39m]), \u001b[38;5;28mint\u001b[39m(image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolution[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m    232\u001b[0m     image \u001b[38;5;241m=\u001b[39m tr\u001b[38;5;241m.\u001b[39mresize(image\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32), ip_size, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, preserve_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m/kaggle/input/qcanet3/QCANet/src/lib/dataset.py:25\u001b[0m, in \u001b[0;36mread_img\u001b[0;34m(path, arr_type)\u001b[0m\n\u001b[1;32m     23\u001b[0m     image \u001b[38;5;241m=\u001b[39m imread(path, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arr_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtif\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 25\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvalid --input_type : \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(arr_type))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/skimage/io/_io.py:53\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m     50\u001b[0m         plugin \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtifffile\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_or_url_context(fname) \u001b[38;5;28;01mas\u001b[39;00m fname:\n\u001b[0;32m---> 53\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcall_plugin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimread\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplugin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplugin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mplugin_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(img, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/skimage/io/manage_plugins.py:205\u001b[0m, in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not find the plugin \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplugin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkind\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/skimage/io/_plugins/imageio_plugin.py:11\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(imageio_imread)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimread\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 11\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43mimageio_imread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWRITEABLE\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     13\u001b[0m         out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mcopy()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/imageio/v3.py:53\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(uri, index, plugin, extension, format_hint, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m index\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mimopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mplugin_kwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m img_file:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(img_file\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcall_kwargs))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/imageio/core/imopen.py:113\u001b[0m, in \u001b[0;36mimopen\u001b[0;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m     request\u001b[38;5;241m.\u001b[39mformat_hint \u001b[38;5;241m=\u001b[39m format_hint\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mio_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextension\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m source \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<bytes>\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(uri, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m uri\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# fast-path based on plugin\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# (except in legacy mode)\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/imageio/core/request.py:247\u001b[0m, in \u001b[0;36mRequest.__init__\u001b[0;34m(self, uri, mode, extension, format_hint, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Request.Mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# Parse what was given\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# Set extension\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extension \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/imageio/core/request.py:407\u001b[0m, in \u001b[0;36mRequest._parse_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_read_request:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# Reading: check that the file exists (but is allowed a dir)\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(fn):\n\u001b[0;32m--> 407\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m fn)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;66;03m# Writing: check that the directory to write to does exist\u001b[39;00m\n\u001b[1;32m    410\u001b[0m     dn \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(fn)\n","\u001b[0;31mFileNotFoundError\u001b[0m: No such file: '/kaggle/input/qcanet-dataset/qcanet-dataset/images/images_raw/train_split.txt'"]}],"source":["train_eval, test_eval, best_score = trainer.training((train_iterator, test_iterator))"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4635605,"sourceId":7894709,"sourceType":"datasetVersion"},{"datasetId":4758625,"sourceId":8065872,"sourceType":"datasetVersion"},{"datasetId":4744588,"sourceId":8071532,"sourceType":"datasetVersion"}],"dockerImageVersionId":30683,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
